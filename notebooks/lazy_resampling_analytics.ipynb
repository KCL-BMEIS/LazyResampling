{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fca04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import ndimage\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "\n",
    "import monai\n",
    "print(monai.__version__, monai.__file__)\n",
    "\n",
    "import monai.transforms.spatial.old_array as old\n",
    "import monai.transforms.spatial.old_dictionary as oldd\n",
    "from monai.transforms.lazy.functional import apply_pending\n",
    "from monai.transforms.spatial.functional import spacing\n",
    "# from monai.utils.mapping_stack import MetaMatrix\n",
    "from monai.transforms import Invert, AddChannel, Compose, Crop, LoadImage, LoadImaged, EnsureChannelFirst, EnsureChannelFirstd\n",
    "from monai.transforms.spatial.array import Flip, RandFlip, Resize, Rotate, RandRotate, Rotate90, RandRotate90, Spacing, Zoom, RandZoom\n",
    "from monai.transforms.spatial.array import RandGridDistortion, Rand2DElastic\n",
    "from monai.transforms.spatial.dictionary import Spacingd, Resized, RandFlipd, RandRotated, RandRotate90d, RandZoomd\n",
    "from monai.transforms.croppad.functional import croppad\n",
    "from monai.transforms.croppad.old_array import RandSpatialCrop\n",
    "from monai.transforms.croppad.array import CropPad\n",
    "from monai.transforms.croppad.old_dictionary import RandSpatialCropd\n",
    "from monai.transforms.croppad.dictionary import RandCropPadd\n",
    "from monai.data.meta_tensor import MetaTensor\n",
    "from monai.losses.dice import DiceLoss\n",
    "# !pip list | grep monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b362151",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images = dict()\n",
    "base_dir_ = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "sample_str_ = 'BRATS_{}_{}.nii.gz'\n",
    "brats_match_ = lambda x: x[:5] == 'BRATS' and x[-7:] == '.nii.gz'\n",
    "\n",
    "def get_source_id(name):\n",
    "    id_ = name.split('.')[0].split('_')[1]\n",
    "    return id_\n",
    "\n",
    "def entry_type(entry):\n",
    "    if 'image' in entry.split('/')[-1]:\n",
    "        return 'image'\n",
    "    return 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbe600-fca0-47c4-b6c7-b1cf23cc88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entry_list(datapath, pattern_match, get_source_id, get_entry_type):\n",
    "    samples = dict()\n",
    "\n",
    "    for r, d, f in os.walk(datapath, pattern_match):\n",
    "        for ff in f:\n",
    "            if pattern_match(os.path.basename(ff)):\n",
    "                value = get_source_id(ff)\n",
    "    #             print(r, ff)\n",
    "                entries = samples.get(value, [])\n",
    "                entries.append(os.path.join(r, ff))\n",
    "                samples[value] = sorted(entries)\n",
    "\n",
    "    entry_list = sorted(list(samples.items()), key=lambda x: x[0])\n",
    "    # print(len(entry_list))\n",
    "    entry_list = [e for e in entry_list if len(e[1]) == 2]\n",
    "    # print(len(entry_list))\n",
    "    return entry_list\n",
    "\n",
    "entries_ = generate_entry_list(base_dir_, brats_match_, get_source_id, entry_type)\n",
    "# print(entries_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef69970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(size, dtype=torch.float32, offset=0):\n",
    "    img = torch.zeros(size, dtype=dtype)\n",
    "    if len(size) == 2:\n",
    "        for j in range(size[0]):\n",
    "            for i in range(size[1]):\n",
    "                img[j, i] = i + j * size[0] + offset\n",
    "    else:\n",
    "        for k in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                for i in range(size[2]):\n",
    "                    img[k, j, i] = i + j * size[0] + k * size[0] * size[1]\n",
    "    return np.expand_dims(img, 0)\n",
    "\n",
    "\n",
    "def load_sample(sample, get_image=True, get_label=True):\n",
    "\n",
    "    img = nib.load(sample[1][0]).get_fdata()\n",
    "    lbl = nib.load(sample[1][1]).get_fdata()\n",
    "\n",
    "    img = np.transpose(img, axes=(3, 0, 1, 2))\n",
    "    lbl = np.expand_dims(lbl, axis=0)\n",
    "\n",
    "    return None if get_image is False else img, None if get_label is False else lbl\n",
    "\n",
    "\n",
    "def plot_datas(datas, cols=4, tight=False, size=20, axis=False, titles=None, font='arial'):\n",
    "    # print(len(datas))\n",
    "    fonts = ('arial', 'timesnewroman')\n",
    "    if font not in fonts:\n",
    "        print(f\"unrecognised font {font}. Must be one of {fonts}\")\n",
    "    if font == 'arial':\n",
    "        fontspec = {'fontname': 'Arial'}\n",
    "    else:\n",
    "        fontspec = {'fontname': 'Times New Roman'}\n",
    "    minv = min([d.min() for d in datas])\n",
    "    maxv = max([d.max() for d in datas])\n",
    "    rows = len(datas) // cols if len(datas) % cols == 0 else len(datas) // cols + 1\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(size, size * rows / cols))\n",
    "    print(\"plot data shape:\", ax.shape)\n",
    "    if rows == 1:\n",
    "        ax = np.expand_dims(ax, axis=0)\n",
    "    if tight == True:\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if titles is not None:\n",
    "        if len(titles) != len(datas):\n",
    "            raise ValueError(\"titles must be the same length as data if set\")\n",
    "\n",
    "    for i_d, d in enumerate(datas):\n",
    "        if axis == False:\n",
    "            ax[i_d // cols, i_d % cols].axis('off')\n",
    "        if titles is not None:\n",
    "            ax[i_d // cols, i_d % cols].set_title(titles[i_d], **fontspec)\n",
    "            ax[i_d // cols, i_d % cols].title.set_fontsize(28)\n",
    "        if len(datas) <= cols:\n",
    "            ax[i_d // cols, i_d % cols].imshow(d[0,...] if len(d.shape) > 2 else d, vmin=minv, vmax=maxv)\n",
    "        else:\n",
    "            ax[i_d // cols, i_d % cols].imshow(d[0,...] if len(d.shape) > 2 else d)\n",
    "\n",
    "def rand_seed(rng):\n",
    "    value = rng.randint(np.int32((1<<31) - 1), dtype=np.int32)\n",
    "#     print(value, type(value))\n",
    "    return value\n",
    "\n",
    "\n",
    "class RNGWrapper(np.random.RandomState):\n",
    "\n",
    "    def __init__(self, tag, rng):\n",
    "        self.tag = tag\n",
    "        self.rng = rng\n",
    "        self.calls = 0\n",
    "\n",
    "    def rand(self, *args, **kwargs):\n",
    "        self.calls += 1\n",
    "        value = self.rng.rand(*args, **kwargs)\n",
    "        print(self.tag, self.calls, value)\n",
    "        return value\n",
    "\n",
    "    def randint(self, *args, **kwargs):\n",
    "        self.calls += 1\n",
    "        value = self.rng.randint(*args, **kwargs)\n",
    "        print(self.tag, self.calls, value)\n",
    "        return value\n",
    "\n",
    "    \n",
    "def find_mid_label_z(label):\n",
    "    \n",
    "    first_z = None\n",
    "    last_z = None\n",
    "    for z in range(label.shape[-1]):\n",
    "        count = np.count_nonzero(label[..., z])\n",
    "        if count > 0:\n",
    "            if first_z is None:\n",
    "                first_z = z\n",
    "            last_z = z\n",
    "    \n",
    "    if first_z is None:\n",
    "        return 0, label.shape[-1], label.shape[-1] // 2\n",
    "\n",
    "    return first_z, last_z, int((first_z + last_z) / 2)\n",
    "\n",
    "\n",
    "def find_mid_label(label):\n",
    "    first_v = [None, None, None]\n",
    "    last_v = [None, None, None]\n",
    "    slice_dv = [lambda im, v: im[:, v, ...],\n",
    "                lambda im, v: im[..., v, :],\n",
    "                lambda im, v: im[..., v]]\n",
    "\n",
    "    for d in range(3):\n",
    "        for v in range(label.shape[d+1]):\n",
    "            count = np.count_nonzero(slice_dv[d](label, v))\n",
    "            if count > 0:\n",
    "                first_v[d] = v if first_v[d] is None else first_v[d]\n",
    "                last_v[d] = v\n",
    "#     print(\"first_v:\", first_v)\n",
    "#     print(\"last_v:\", last_v)\n",
    "    if first_v[0] == None:\n",
    "        return tuple((0, label.shape[d+1], label.shape[d+1] // 2) for d in range(3))\n",
    "    \n",
    "    return tuple((first_v[d], last_v[d], (last_v[d] + first_v[d]) // 2) for d in range(3))\n",
    "\n",
    "\n",
    "def sanitized_range_from_extents(mid_v, max_v, range_v):\n",
    "    half_range = range_v // 2\n",
    "    if mid_v - half_range < 0:\n",
    "        return 0, range_v\n",
    "    if mid_v + half_range >= max_v:\n",
    "        return max_v - range_v, max_v\n",
    "    return mid_v - half_range, mid_v + half_range\n",
    "\n",
    "\n",
    "# def entropy(vol):\n",
    "#     jh, _ = np.histogram(vol.ravel(), bins=256, density=True)\n",
    "#     # Add epsillon values to compensate for 0 bins\n",
    "#     jh = jh + np.finfo(np.float32).eps\n",
    "#     # Compute and return the joint entropy\n",
    "#     return np.sum(jh.ravel()*np.log(jh.ravel()))\n",
    "\n",
    "\n",
    "def entropy(img_data):\n",
    "    hist = np.histogram(img_data, bins=256)\n",
    "    p = hist[0]\n",
    "    p = p / np.sum(p)\n",
    "    e = -np.sum(np.where(p != 0, p * np.log2(p), 0))\n",
    "    return e\n",
    "\n",
    "class Dots:\n",
    "    def __init__(self, length=10):\n",
    "        self._cur = 0\n",
    "        self._length = length\n",
    "\n",
    "    def dot(self):\n",
    "        if self._cur > 0 and self._cur % self._length == 0:\n",
    "            print()\n",
    "        print(\".\", end=\"\")\n",
    "        self._cur += 1\n",
    "\n",
    "    def done(self):\n",
    "        if self._cur > 0:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trad_pipeline():\n",
    "\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "\n",
    "    resized = oldd.Resized(keys=keys, spatial_size=(192, 192, 72), mode=(\"area\", \"nearest\"))\n",
    "    randflipd = oldd.RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2])\n",
    "    randflipd.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    rotate90d = oldd.RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1))\n",
    "    rotate90d.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    zoomd = oldd.RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"area\", \"nearest\"), keep_size=True)\n",
    "    zoomd.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    rotated = oldd.RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True)\n",
    "    rotated.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    pipeline = Compose([resized, randflipd, rotate90d, zoomd, rotated])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def trad_pipeline_patch_first():\n",
    "\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "    randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "    zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "    patch_seed = rand_seed(masterrng)\n",
    "    # print(\"lazy patch seed:\", patch_seed)\n",
    "    patchrng = np.random.RandomState(patch_seed)\n",
    "\n",
    "    patchd = RandSpatialCropd(keys=keys, roi_size=(160, 160, 155), random_size=False)\n",
    "    patchd.set_random_state(state=patchrng)\n",
    "    resized = oldd.Spacingd(keys=keys, pixdim=(1.0, 1.0, 155/72), mode=(\"bilinear\", \"nearest\"))\n",
    "    randflipd = oldd.RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2])\n",
    "    randflipd.set_random_state(state=randfliprng)\n",
    "    rotate90d = oldd.RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1))\n",
    "    rotate90d.set_random_state(state=rotate90rng)\n",
    "    zoomd = oldd.RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"area\", \"nearest\"), keep_size=True)\n",
    "    zoomd.set_random_state(state=zoomrng)\n",
    "    rotated = oldd.RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True)\n",
    "    rotated.set_random_state(state=rotaterng)\n",
    "    pipeline = Compose([patchd, resized, randflipd, rotate90d, zoomd, rotated])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def trad_pipeline_patch_last():\n",
    "\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "    randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "    zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "    patch_seed = rand_seed(masterrng)\n",
    "    print(\"lazy patch seed:\", patch_seed)\n",
    "    patchrng = RNGWrapper(\"trad\", np.random.RandomState(patch_seed))\n",
    "\n",
    "    resized = oldd.Spacingd(keys=keys, pixdim=(1.0, 1.0, 155/72), mode=(\"bilinear\", \"nearest\"))\n",
    "    randflipd = oldd.RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2])\n",
    "    randflipd.set_random_state(state=randfliprng)\n",
    "    rotate90d = oldd.RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1))\n",
    "    rotate90d.set_random_state(state=rotate90rng)\n",
    "    zoomd = oldd.RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"area\", \"nearest\"), keep_size=True)\n",
    "    zoomd.set_random_state(state=zoomrng)\n",
    "    rotated = oldd.RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True)\n",
    "    rotated.set_random_state(state=rotaterng)\n",
    "    patchd = RandSpatialCropd(keys=keys, roi_size=(160, 160, 72), random_size=False)\n",
    "    patchd.set_random_state(state=patchrng)\n",
    "    pipeline = Compose([resized, randflipd, rotate90d, zoomd, rotated, patchd])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def trad_pipeline_label_only():\n",
    "\n",
    "    print(\"trad_pipeline_label_only\")\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "    loadimage = LoadImage(image_only=True)\n",
    "    ensurech = EnsureChannelFirst()\n",
    "    resize = old.Resize(spatial_size=(192, 192, 72), mode=\"nearest\")\n",
    "    randflip = old.RandFlip(prob=0.5, spatial_axis=[1, 2])\n",
    "    # randflip.set_random_state(state=RNGWrapper(\"t\", np.random.RandomState(rand_seed(masterrng))))\n",
    "    randflip.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    rotate90 = old.RandRotate90(prob=0.5, spatial_axes=(0, 1))\n",
    "    rotate90.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    zoom = old.RandZoom(prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=\"nearest\", keep_size=True)\n",
    "    zoom.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    rotate = old.RandRotate(prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=\"nearest\", align_corners=True)\n",
    "    rotate.set_random_state(state=np.random.RandomState(rand_seed(masterrng)))\n",
    "    pipeline = Compose([loadimage, ensurech, resize, randflip, rotate90, zoom, rotate])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def lazy_pipeline(lazy=True):\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "\n",
    "    pipeline = Compose([\n",
    "            Resized(keys=keys, spatial_size=(192, 192, 72), mode=(\"bilinear\", \"nearest\"), lazy=lazy),\n",
    "            RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2], lazy=lazy,\n",
    "                      state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1), lazy=lazy,\n",
    "                          state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"bilinear\", \"nearest\"), keep_size=True, lazy=lazy,\n",
    "                      state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True, lazy=lazy,\n",
    "                        state=np.random.RandomState(rand_seed(masterrng))),        \n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# def lazy_pipeline_patch_first(lazy=True):\n",
    "#     keys = ('image', 'label')\n",
    "#     masterrng = np.random.RandomState(12345678)\n",
    "#     randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     patch_seed = rand_seed(masterrng)\n",
    "#     print(\"lazy patch seed:\", patch_seed)\n",
    "#     patchrng = np.random.RandomState(patch_seed)\n",
    "\n",
    "#     pipeline = Compose([\n",
    "#             RandCropPadd(keys=keys, sizes=(160, 160, 155), lazy_evaluation=lazy, state=patchrng),\n",
    "#             Spacingd(keys=keys, pixdim=(1.0, 1.0, 155/72), mode=(\"bilinear\", \"nearest\"), lazy_evaluation=lazy),\n",
    "#             RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2], lazy_evaluation=lazy, state=randfliprng),\n",
    "#             RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1), lazy_evaluation=lazy, state=rotate90rng),\n",
    "#             RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"bilinear\", \"nearest\"), keep_size=True, lazy_evaluation=lazy, state=zoomrng),\n",
    "#             RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True, lazy_evaluation=lazy, state=rotaterng),        \n",
    "#     ])\n",
    "    \n",
    "#     return pipeline\n",
    "\n",
    "\n",
    "def lazy_pipeline_patch_first(lazy=True, **kwargs):\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "    randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "    zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "    patch_seed = rand_seed(masterrng)\n",
    "    # print(\"lazy patch seed:\", patch_seed)\n",
    "    patchrng = np.random.RandomState(patch_seed)\n",
    "\n",
    "    pipeline = Compose([\n",
    "        RandCropPadd(keys=keys, sizes=(160, 160, 155), lazy=lazy, state=patchrng),\n",
    "        Resized(keys=keys, spatial_size=(160, 160, 72), mode=(\"bilinear\", \"nearest\"), lazy=lazy),\n",
    "        RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2], lazy=lazy, state=randfliprng),\n",
    "        RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1), lazy=lazy, state=rotate90rng),\n",
    "        RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"bilinear\", \"nearest\"), keep_size=True,\n",
    "                  lazy=lazy, state=zoomrng),\n",
    "        RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi / 4, torch.pi / 4), mode=(\"bilinear\", \"nearest\"),\n",
    "                    align_corners=True, lazy=lazy, state=rotaterng),\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# def lazy_pipeline_patch_last(lazy=True):\n",
    "#     keys = ('image', 'label')\n",
    "#     masterrng = np.random.RandomState(12345678)\n",
    "#     randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "#     patch_seed = rand_seed(masterrng)\n",
    "#     print(\"lazy patch seed:\", patch_seed)\n",
    "#     patchrng = np.random.RandomState(patch_seed)\n",
    "\n",
    "#     pipeline = Compose([\n",
    "#             Spacingd(keys=keys, pixdim=(1.0, 1.0, 155/72), mode=(\"bilinear\", \"nearest\"), lazy_evaluation=lazy),\n",
    "#             RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2], lazy_evaluation=lazy, state=randfliprng),\n",
    "#             RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1), lazy_evaluation=lazy, state=rotate90rng),\n",
    "#             RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"bilinear\", \"nearest\"), keep_size=True, lazy_evaluation=lazy, state=zoomrng),\n",
    "#             RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=(\"bilinear\", \"nearest\"), align_corners=True, lazy_evaluation=lazy, state=rotaterng),        \n",
    "#             RandCropPadd(keys=keys, sizes=(160, 160, 72), lazy_evaluation=lazy, state=patchrng),\n",
    "#     ])\n",
    "    \n",
    "#     return pipeline\n",
    "\n",
    "\n",
    "def lazy_pipeline_patch_last(lazy=True, **kwargs):\n",
    "\n",
    "    keys = ('image', 'label')\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "    randfliprng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotate90rng = np.random.RandomState(rand_seed(masterrng))\n",
    "    zoomrng = np.random.RandomState(rand_seed(masterrng))\n",
    "    rotaterng = np.random.RandomState(rand_seed(masterrng))\n",
    "    patch_seed = rand_seed(masterrng)\n",
    "    print(\"lazy patch seed:\", patch_seed)\n",
    "    patchrng = RNGWrapper(\"lazy\", np.random.RandomState(patch_seed))\n",
    "\n",
    "    pipeline = Compose([\n",
    "        Resized(keys=keys, spatial_size=(240, 240, 72), mode=(\"bilinear\", \"nearest\"), lazy=lazy),\n",
    "        RandFlipd(keys=keys, prob=0.5, spatial_axis=[1, 2], lazy=lazy, state=randfliprng),\n",
    "        RandRotate90d(keys=keys, prob=0.5, spatial_axes=(0, 1), lazy=lazy, state=rotate90rng),\n",
    "        RandZoomd(keys=keys, prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=(\"bilinear\", \"nearest\"), keep_size=True,\n",
    "                  lazy=lazy, state=zoomrng),\n",
    "        RandRotated(keys=keys, prob=1.0, range_z=(-torch.pi / 4, torch.pi / 4), mode=(\"bilinear\", \"nearest\"),\n",
    "                    align_corners=True, lazy=lazy, state=rotaterng),\n",
    "        RandCropPadd(keys=keys, sizes=(160, 160, 72), lazy=lazy, state=patchrng),\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def lazy_pipeline_label_only(lazy=True):\n",
    "    masterrng = np.random.RandomState(12345678)\n",
    "\n",
    "    print(\"lazy_pipeline_label_only\")\n",
    "    pipeline = Compose([\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            Resize(spatial_size=(192, 192, 72), mode=\"nearest\", lazy=lazy),\n",
    "            RandFlip(prob=0.5, spatial_axis=[1, 2], lazy=lazy,\n",
    "                     state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            # RandFlip(prob=0.5, spatial_axis=[1, 2], lazy=lazy,\n",
    "            #          state=RNGWrapper(\"l\", np.random.RandomState(rand_seed(masterrng)))),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 1), lazy=lazy,\n",
    "                         state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            RandZoom(prob=1.0, min_zoom=0.75, max_zoom=1.25, mode=\"nearest\", keep_size=True, lazy=lazy,\n",
    "                     state=np.random.RandomState(rand_seed(masterrng))),\n",
    "            RandRotate(prob=1.0, range_z=(-torch.pi/4, torch.pi/4), mode=\"nearest\", align_corners=True, lazy=lazy,\n",
    "                       state=np.random.RandomState(rand_seed(masterrng))),        \n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090b8aa",
   "metadata": {},
   "source": [
    "# Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841552eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = np.expand_dims(np.linspace(0, 31, 32), 0)\n",
    "data_2d = get_img((32, 24))\n",
    "data_3d = get_img((32, 24, 16))\n",
    "\n",
    "datas = []\n",
    "\n",
    "result = torch.nn.functional.interpolate(datas, )\n",
    "datas.append()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7e0ed",
   "metadata": {},
   "source": [
    "# Pad Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d = get_img((32, 24))\n",
    "data_2d[0,7:9,7:9] = 1096\n",
    "data_2d[0,15:17,:] = 1160\n",
    "data_2d[0,0,:] = 1224\n",
    "data_2d[0,:,0] = 1286\n",
    "data_2d = np.squeeze(data_2d, axis=0)\n",
    "\n",
    "datas = []\n",
    "border = (16, 12)\n",
    "datas.append(data_2d)\n",
    "np_padding_modes = ('constant', 'edge', 'linear_ramp', 'maximum', 'mean', 'median', 'minimum', 'reflect', 'symmetric', 'wrap', 'empty')\n",
    "for p in np_padding_modes:\n",
    "    result = np.pad(data_2d, border, mode=p)\n",
    "    datas.append(result)\n",
    "\n",
    "ndi_padding_modes = ('constant', 'grid-constant', 'nearest', 'reflect', 'mirror', 'grid-mirror', 'wrap', 'grid-wrap')\n",
    "for p in ndi_padding_modes:\n",
    "    affine = np.eye(3)\n",
    "    affine[0, 2] = -12\n",
    "    affine[1, 2] = -9\n",
    "#     affine[0, 0] = 0.5\n",
    "#     affine[1, 1] = 0.5\n",
    "    result = ndimage.affine_transform(data_2d, affine, output_shape=(64, 48), mode=p, order=0)\n",
    "# for p in ndi_padding_modes:\n",
    "#     xs = np.arange(data_2d.shape[0] * data_2d.shape[1]) // data_2d.shape[0]\n",
    "#     ys = np.arange(data_2d.shape[0] * data_2d.shape[1]) % data_2d.shape[1]\n",
    "#     result = ndimage.map_coordinates(data_2d, coordinates=[xs, ys], order=0, mode=p).reshape(32, 24)\n",
    "#     # print(result.shape, result)\n",
    "    datas.append(result)\n",
    "\n",
    "plot_datas(datas, cols=5, axis=True, titles=('base',) + np_padding_modes + ndi_padding_modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f5a8e7",
   "metadata": {},
   "source": [
    "# Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549766ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "print(data.shape)\n",
    "\n",
    "datas = []\n",
    "print(\"rotate 0\")\n",
    "angle = torch.pi / 8\n",
    "print(old.__file__)\n",
    "r1 = old.Rotate(angle,\n",
    "            keep_size=True,\n",
    "            padding_mode=\"zeros\")\n",
    "\n",
    "datas.append(data)\n",
    "data1 = r1(data)\n",
    "datas.append(data1)\n",
    "print(\"data1:\", data1.shape, data1)\n",
    "\n",
    "print(\"rotate 1\")\n",
    "r2 = Rotate(angle,\n",
    "            padding_mode=\"zeros\",\n",
    "            keep_size=True,\n",
    "            lazy=False)\n",
    "data2 = r2(data)\n",
    "datas.append(data2)\n",
    "print(\"data2:\", data2.shape)\n",
    "\n",
    "print(\"rotate 2\")\n",
    "r3 = Rotate(angle,\n",
    "            padding_mode=\"zeros\",\n",
    "            keep_size=True)\n",
    "r3.lazy_evalution = True\n",
    "data3a = r3(data)\n",
    "data3 = apply_pending(data3a)\n",
    "datas.append(data3)\n",
    "print(\"data3:\", data3.shape)\n",
    "\n",
    "diff2_1 = data2 - data1\n",
    "datas.append(diff2_1)\n",
    "diff3_1 = data3 - data1\n",
    "datas.append(diff3_1)\n",
    "diff3_2 = data3 - data2\n",
    "print(np.unique(diff3_1, return_counts=True))\n",
    "datas.append(diff3_2)\n",
    "plot_datas(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3f82f",
   "metadata": {},
   "source": [
    "# Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbe1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "angle = torch.pi / 8\n",
    "def old_rotate(keep_size=True):\n",
    "    z1 = old.Rotate(angle, mode=\"nearest\", padding_mode=\"zeros\", keep_size=True)\n",
    "    z2 = old.Rotate(angle, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=True)\n",
    "    z3 = old.Rotate(angle, mode=\"nearest\", padding_mode=\"zeros\", keep_size=False)\n",
    "    z4 = old.Rotate(angle, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=False)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_rotate(keep_size=True):\n",
    "    z1 = Rotate(angle, mode=\"nearest\", padding_mode=\"zeros\", keep_size=True, lazy=False)\n",
    "    z2 = Rotate(angle, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=True, lazy=False)\n",
    "    z3 = Rotate(angle, mode=\"nearest\", padding_mode=\"zeros\", keep_size=False, lazy=False)\n",
    "    z4 = Rotate(angle, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=False, lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        print(data1.affine)\n",
    "        print(data1.affine)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_rotate(False)(data)\n",
    "new_results = new_rotate(False)(data)\n",
    "\n",
    "diffs = []\n",
    "for o, n in zip(old_results, new_results):\n",
    "    diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c0951",
   "metadata": {},
   "source": [
    "# Rotate by 90 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "data = torch.tensor(data)\n",
    "\n",
    "datas= []\n",
    "datas.append(data)\n",
    "data = data.flip([1])\n",
    "datas.append(data)\n",
    "data = data.permute((0, 2, 1))\n",
    "datas.append(data)\n",
    "\n",
    "plot_datas(datas, cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa76909",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "def old_rotate(keep_size=True):\n",
    "    z1 = old.Rotate(torch.pi / 2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=True)\n",
    "    z2 = old.Rotate(torch.pi, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=True)\n",
    "    z3 = old.Rotate(3 * torch.pi / 2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=False)\n",
    "    z4 = old.Rotate(2 * torch.pi, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=False)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_rotate(keep_size=True):\n",
    "    z1 = Rotate(torch.pi / 2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=True, lazy=False)\n",
    "    z2 = Rotate(torch.pi, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=True, lazy=False)\n",
    "    z3 = Rotate(3 * torch.pi / 2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=False, lazy=False)\n",
    "    z4 = Rotate(2 * torch.pi, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=False, lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        print(data1.affine)\n",
    "        print(data1.affine)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_rotate(False)(data)\n",
    "new_results = new_rotate(False)(data)\n",
    "\n",
    "diffs = []\n",
    "for o, n in zip(old_results, new_results):\n",
    "    diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3936806",
   "metadata": {},
   "source": [
    "# Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9457338",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "def old_zoom(keep_size=True):\n",
    "    z1 = old.Zoom(2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=keep_size)\n",
    "    z2 = old.Zoom(2, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=keep_size)\n",
    "    z3 = old.Zoom(0.5, mode=\"nearest\", padding_mode=\"constant\", keep_size=keep_size)\n",
    "    z4 = old.Zoom(0.5, mode=\"bilinear\", padding_mode=\"constant\", keep_size=keep_size)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_zoom(keep_size=True):\n",
    "    z1 = Zoom(2, mode=\"nearest\", padding_mode=\"zeros\", keep_size=keep_size, lazy=False)\n",
    "    z2 = Zoom(2, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=keep_size, lazy=False)\n",
    "    z3 = Zoom(0.5, mode=\"nearest\", padding_mode=\"zeros\", keep_size=keep_size, lazy=False)\n",
    "    z4 = Zoom(0.5, mode=\"bilinear\", padding_mode=\"zeros\", keep_size=keep_size, lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = z1(imgs)\n",
    "        print(data1.affine)\n",
    "        print(data1.affine)\n",
    "        datas.append(data1)\n",
    "        data2 = z2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = z3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = z4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_zoom(True)(data)\n",
    "new_results = new_zoom(True)(data)\n",
    "\n",
    "diffs = []\n",
    "# for o, n in zip(old_results, new_results):\n",
    "#     diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, axis=True, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84a63c",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "zoom_in = (48, 48)\n",
    "zoom_out = (24, 24)\n",
    "def old_resize():\n",
    "    t1 = old.Resize(zoom_in, mode=\"nearest\")\n",
    "    t2 = old.Resize(zoom_in, mode=\"bilinear\")\n",
    "    t3 = old.Resize(zoom_out, mode=\"nearest\")\n",
    "    t4 = old.Resize(zoom_out, mode=\"bilinear\")\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = t4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_resize():\n",
    "    t1 = Resize(zoom_in, mode=\"nearest\", lazy=False)\n",
    "    t2 = Resize(zoom_in, mode=\"bilinear\", lazy=False)\n",
    "    t3 = Resize(zoom_out, mode=\"nearest\", lazy=False)\n",
    "    t4 = Resize(zoom_out, mode=\"bilinear\", lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "#         print(data1.affine)\n",
    "#         data1.pending_operations[0].matrix.data[0,0] = 0.5\n",
    "#         data1.pending_operations[0].matrix.data[1,1] = 0.5\n",
    "#         print(data1.pending_operations[0].matrix.data)\n",
    "#         data1 = apply_pending(data1)[0]\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = t4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_resize()(data)\n",
    "new_results = new_resize()(data)\n",
    "\n",
    "diffs = []\n",
    "# for o, n in zip(old_results, new_results):\n",
    "#     diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c317d23",
   "metadata": {},
   "source": [
    "# Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa757581",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "dest_pixdim = (1.0, 1.0)\n",
    "big_src_pixdim = (2.0, 2.0)\n",
    "sml_src_pixdim = (0.5, 0.5)\n",
    "\n",
    "def old_spacing():\n",
    "    t1 = old.Spacing(dest_pixdim, mode=\"nearest\")\n",
    "    t2 = old.Spacing(dest_pixdim, mode=\"bilinear\")\n",
    "    t3 = old.Spacing(dest_pixdim, mode=\"nearest\")\n",
    "    t4 = old.Spacing(dest_pixdim, mode=\"bilinear\")\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine = torch.tensor([[big_src_pixdim[0], 0.0, 0.0, 0.0],\n",
    "                                  [0.0, big_src_pixdim[1], 0.0, 0.0],\n",
    "                                  [0.0, 0.0, 1.0, 0.0],\n",
    "                                  [0.0, 0.0, 0.0, 1.0]])\n",
    "        data1 = t1(mt)\n",
    "        datas.append(data1)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine = torch.tensor([[big_src_pixdim[0], 0.0, 0.0, 0.0],\n",
    "                                  [0.0, big_src_pixdim[1], 0.0, 0.0],\n",
    "                                  [0.0, 0.0, 1.0, 0.0],\n",
    "                                  [0.0, 0.0, 0.0, 1.0]])\n",
    "        data2 = t2(mt)\n",
    "        datas.append(data2)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine = torch.tensor([[sml_src_pixdim[0], 0.0, 0.0, 0.0],\n",
    "                                  [0.0, sml_src_pixdim[1], 0.0, 0.0],\n",
    "                                  [0.0, 0.0, 1.0, 0.0],\n",
    "                                  [0.0, 0.0, 0.0, 1.0]])\n",
    "        data3 = t3(mt)\n",
    "        datas.append(data3)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine = torch.tensor([[sml_src_pixdim[0], 0.0, 0.0, 0.0],\n",
    "                                  [0.0, sml_src_pixdim[1], 0.0, 0.0],\n",
    "                                  [0.0, 0.0, 1.0, 0.0],\n",
    "                                  [0.0, 0.0, 0.0, 1.0]])\n",
    "        data4 = t4(mt)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_spacing():\n",
    "    t1 = Spacing(dest_pixdim, mode=\"nearest\", lazy=False)\n",
    "#     t1 = lambda x: spacing(x, dest_pixdim, big_src_pixdim, mode=\"nearest\", padding_mode=\"zeros\", lazy_evaluation=False)\n",
    "    t2 = Spacing(dest_pixdim, mode=\"bilinear\", lazy=False)\n",
    "#     t2 = lambda x: spacing(x, dest_pixdim, big_src_pixdim, mode=\"bilinear\", padding_mode=\"zeros\", lazy_evaluation=False)\n",
    "    t3 = Spacing(dest_pixdim, mode=\"nearest\", lazy=False)\n",
    "#     t3 = lambda x: spacing(x, dest_pixdim, sml_src_pixdim, mode=\"nearest\", padding_mode=\"zeros\", lazy_evaluation=False)\n",
    "    t4 = Spacing(dest_pixdim, mode=\"bilinear\", lazy=False)\n",
    "#     t4 = lambda x: spacing(x, dest_pixdim, sml_src_pixdim, mode=\"bilinear\", padding_mode=\"zeros\", lazy_evaluation=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine[0, 0] = big_src_pixdim[0]\n",
    "        mt.affine[1, 1] = big_src_pixdim[1]\n",
    "        data1 = t1(mt)\n",
    "        datas.append(data1)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine[0, 0] = big_src_pixdim[0]\n",
    "        mt.affine[1, 1] = big_src_pixdim[1]\n",
    "        data2 = t2(mt)\n",
    "        datas.append(data2)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine[0, 0] = sml_src_pixdim[0]\n",
    "        mt.affine[1, 1] = sml_src_pixdim[1]\n",
    "        data3 = t3(mt)\n",
    "        datas.append(data3)\n",
    "        mt = MetaTensor(imgs)\n",
    "        mt.affine[0, 0] = sml_src_pixdim[0]\n",
    "        mt.affine[1, 1] = sml_src_pixdim[1]\n",
    "        data4 = t4(mt)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_spacing()(data)\n",
    "new_results = new_spacing()(data)\n",
    "\n",
    "for d in old_results:\n",
    "    print(d.shape)\n",
    "\n",
    "for d in new_results:\n",
    "    print(d.shape)\n",
    "\n",
    "diffs = []\n",
    "# for o, n in zip(old_results, new_results):\n",
    "#     diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf55af",
   "metadata": {},
   "source": [
    "# Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9db7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "def old_resize():\n",
    "    t1 = old.Flip(0)\n",
    "    t2 = old.Flip(1)\n",
    "    t3 = old.Flip((0, 1))\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_resize():\n",
    "    t1 = Flip(0, lazy=False)\n",
    "    t2 = Flip(1, lazy=False)\n",
    "    t3 = Flip((0, 1), lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_resize()(data)\n",
    "new_results = new_resize()(data)\n",
    "\n",
    "diffs = []\n",
    "# for o, n in zip(old_results, new_results):\n",
    "#     diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=4, axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bde855",
   "metadata": {},
   "source": [
    "# Rotate90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 24))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "def old_resize():\n",
    "    t1 = old.Rotate90(0)\n",
    "    t2 = old.Rotate90(1)\n",
    "    t3 = old.Rotate90(2)\n",
    "    t4 = old.Rotate90(3)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = t4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "\n",
    "    return _inner\n",
    "\n",
    "def new_resize():\n",
    "    t1 = Rotate90(0, lazy=False)\n",
    "    t2 = Rotate90(1, lazy=False)\n",
    "    t3 = Rotate90(2, lazy=False)\n",
    "    t4 = Rotate90(3, lazy=False)\n",
    "\n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = t1(imgs)\n",
    "#         print(data1.affine)\n",
    "#         data1.pending_operations[0].matrix.data[0,0] = 0.5\n",
    "#         data1.pending_operations[0].matrix.data[1,1] = 0.5\n",
    "#         print(data1.pending_operations[0].matrix.data)\n",
    "#         data1 = apply_pending(data1)[0]\n",
    "        datas.append(data1)\n",
    "        data2 = t2(imgs)\n",
    "        datas.append(data2)\n",
    "        data3 = t3(imgs)\n",
    "        datas.append(data3)\n",
    "        data4 = t4(imgs)\n",
    "        datas.append(data4)\n",
    "        return datas\n",
    "    \n",
    "    return _inner\n",
    "\n",
    "old_results = old_resize()(data)\n",
    "new_results = new_resize()(data)\n",
    "\n",
    "diffs = []\n",
    "# for o, n in zip(old_results, new_results):\n",
    "#     diffs.append(n - o)\n",
    "\n",
    "plot_datas(old_results + new_results + diffs, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90117061",
   "metadata": {},
   "source": [
    "# Resize / Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32))\n",
    "data[0,7:9,7:9] = 1096\n",
    "data[0,15:17,:] = 1160\n",
    "data[0,0,:] = 1224\n",
    "data[0,:,0] = 1286\n",
    "print(data.shape)\n",
    "\n",
    "def old_rotate_then_crop():\n",
    "    c1 = Crop()\n",
    "    r1 = old.Rotate(torch.pi / 4, keep_size=False, padding_mode=\"zeros\")\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = r1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = c1(data1, slices=(slice(0,16), slice(0,16)))\n",
    "        datas.append(data2)\n",
    "        return datas\n",
    "    return _inner\n",
    "\n",
    "def old_crop_then_rotate():\n",
    "    c1 = Crop()\n",
    "    r1 = old.Rotate(torch.pi / 4, keep_size=False, padding_mode=\"zeros\")\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = c1(imgs, slices=(slice(0,16), slice(0,16)))\n",
    "        datas.append(data1)\n",
    "        data2 = r1(data1)\n",
    "        datas.append(data2)\n",
    "        return datas\n",
    "    return _inner\n",
    "\n",
    "def new_rotate_then_crop(lazy=False):\n",
    "    r1 = Rotate(torch.pi / 4, keep_size=False, padding_mode=\"zeros\", lazy=lazy)\n",
    "    c1 = CropPad(padding_mode=\"zeros\", lazy=False)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = r1(imgs)\n",
    "        datas.append(data1)\n",
    "        data2 = c1(data1, slices=(slice(0,16), slice(0,16)))\n",
    "        datas.append(data2)\n",
    "        return datas\n",
    "    return _inner\n",
    "\n",
    "def new_crop_then_rotate(lazy=False):\n",
    "    c1 = CropPad(padding_mode=\"zeros\", lazy=lazy)\n",
    "    r1 = Rotate(torch.pi / 4, keep_size=False, padding_mode=\"zeros\", lazy=False)\n",
    "    \n",
    "    def _inner(imgs):\n",
    "        datas = []\n",
    "        datas.append(imgs)\n",
    "        data1 = c1(imgs, slices=(slice(0,16), slice(0,16)))\n",
    "        datas.append(data1)\n",
    "        data2 = r1(data1)\n",
    "        datas.append(data2)\n",
    "        return datas\n",
    "    return _inner\n",
    "\n",
    "# crops = (old_rotate_then_crop(), new_rotate_then_crop(False), new_rotate_then_crop(True),\n",
    "#          old_crop_then_rotate(), new_crop_then_rotate(False), new_crop_then_rotate(True))\n",
    "crops = (old_rotate_then_crop(), old_crop_then_rotate(), new_crop_then_rotate(True))\n",
    "for t in crops:\n",
    "    datas = t(data)\n",
    "    print(datas[0].shape)\n",
    "    plot_datas(datas, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120480e",
   "metadata": {},
   "source": [
    "# Functional croppad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_functional_croppad():\n",
    "    data = get_img((16, 16))\n",
    "    data[0,7:9,7:9] = 1096\n",
    "    data[0,15:17,:] = 1160\n",
    "    data[0,0,:] = 1224\n",
    "    data[0,:,0] = 1286\n",
    "    print(data.shape)\n",
    "\n",
    "    img00 = croppad(data, slices=(slice(0, 8), slice(0, 8)), padding_mode=\"zeros\")\n",
    "#     img00.push_pending_transform(MetaMatrix(tx, md))\n",
    "    actual00 = apply_pending(img00)\n",
    "\n",
    "    img10 = croppad(data, slices=(slice(1, 9), slice(0, 8)), padding_mode=\"zeros\")\n",
    "#     img10.push_pending_transform(MetaMatrix(tx, md))\n",
    "    actual10 = apply_pending(img10)\n",
    "\n",
    "    c = Crop()\n",
    "    actual10_2 = c(data, slices=(slice(1, 9), slice(0, 8)))\n",
    "\n",
    "    plot_datas([data, actual00, actual10, actual10_2])\n",
    "\n",
    "do_functional_croppad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31da93a",
   "metadata": {},
   "source": [
    "# Trad vs lazy - forward pass results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe933fc",
   "metadata": {},
   "source": [
    "## Entropy - whole volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad343a-da42-48ef-a741-21af1c913e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy test\n",
    "import numpy as np\n",
    "\n",
    "entropy_vals = list()\n",
    "\n",
    "def entropy_test(samples):\n",
    "    img, lbl = get_image_and_lab\n",
    "    img = nib.load(sample[1][0])\n",
    "    img_data = img.get_fdata()\n",
    "    hist = np.histogram(img_data, bins=256)\n",
    "    p = hist[0]\n",
    "    p = p / np.sum(p)\n",
    "    print(np.sum(p))\n",
    "    e = -np.sum(np.where(p != 0, p * np.log2(p), 0))\n",
    "    print(e)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(24, 8))\n",
    "    ax.set_yscale('log')\n",
    "    ax.plot(hist[1][:-1], p)\n",
    "\n",
    "\n",
    "entropy_test(entries_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d354815-c227-4775-b5cd-f02d0479d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def show_images(sample):\n",
    "    img, lbl = load_sample(sample)\n",
    "    ddict = {'image': img, 'label': lbl}\n",
    "\n",
    "    # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline()\n",
    "    lp = lazy_pipeline(True)\n",
    "\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['image'])\n",
    "    p_label_exts = find_mid_label(ddict['image'])\n",
    "    # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "    p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['image'].shape[1], int(100 * 240 / 192)))\n",
    "    p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['image'].shape[2], int(100 * 240 / 192)))\n",
    "    # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "    num_samples = 8\n",
    "    print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    # vols = []\n",
    "    results = []\n",
    "    t_time = 0\n",
    "    l_time = 0\n",
    "    for i in range(num_samples):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_time += time.time() - t_start\n",
    "        # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "        t_label_exts = find_mid_label(t_out['image'])\n",
    "        # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "        t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['image'].shape[1], 100))\n",
    "        t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['image'].shape[2], 100))\n",
    "        # print(\"extents:\", t_slice_x, t_slice_y)\n",
    "        # print(t_first_z, t_last_z, t_mid_slice)\n",
    "\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_time += time.time() - l_start\n",
    "        # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "        l_label_exts = find_mid_label(l_out['image'])\n",
    "        # print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "        l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['image'].shape[1], 100))\n",
    "        l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['image'].shape[2], 100))\n",
    "        # print(\"extents:\", l_slice_x, l_slice_y)\n",
    "        # print(l_first_z, l_last_z, l_mid_slice)\n",
    "    \n",
    "        # vols.extend([ddict['image'][0, ...],\n",
    "        #              t_out['image'][1, ...],\n",
    "        #              l_out['image'][2, ...]])\n",
    "\n",
    "        results.extend([ddict['image'][0, ..., pre_mid_slice],\n",
    "                        t_out['image'][0, ..., t_label_exts[2][2]],\n",
    "                        l_out['image'][0, ..., l_label_exts[2][2]]])\n",
    "\n",
    "    print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    plot_datas(results, 3, tight=True, size=12)\n",
    "    display_images['forward_segs_whole'] = copy.deepcopy(results[0:3])\n",
    "\n",
    "show_images(entries_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e7a11-7f93-48ad-83d1-a0b3eab336c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_entropy_whole_pipeline(sample): # base_dir, sample_str):\n",
    "    img, lbl = load_sample(sample)\n",
    "    img = img[0:1, ...]\n",
    "    ddict = {'image': img, 'label': lbl}\n",
    "\n",
    "    tp = trad_pipeline()\n",
    "    lp = lazy_pipeline(True)\n",
    "\n",
    "    num_samples = 8\n",
    "    vols = []\n",
    "    t_times = []\n",
    "    l_times = []\n",
    "    for i in range(num_samples):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_times.append(time.time() - t_start)\n",
    "\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_times.append(time.time() - l_start)\n",
    "\n",
    "        vols.extend([ddict['image'][0, ...],\n",
    "                     t_out['image'][0, ...],\n",
    "                     l_out['image'][0, ...]])\n",
    "\n",
    "    # print(\"len(vols) =\", len(vols))\n",
    "    e_origs = list()\n",
    "    e_trads = list()\n",
    "    e_lazys = list()\n",
    "    for i_r in range(8):\n",
    "        ovol = vols[i_r * 3]\n",
    "        tvol = vols[i_r * 3 + 1]\n",
    "        lvol = vols[i_r * 3 + 2]\n",
    "        e_orig = entropy(ovol)\n",
    "        e_trad = entropy(tvol)\n",
    "        e_lazy = entropy(lvol)\n",
    "        # print(\"ovol:\", e_orig,\n",
    "        #       \"tvol:\", e_trad,\n",
    "        #       \"lvol:\", e_lazy)\n",
    "        e_origs.append(e_orig)\n",
    "        e_trads.append(e_trad)\n",
    "        e_lazys.append(e_lazy)\n",
    "\n",
    "    # print(f\"trad time: {sum(t_times) / len(t_times)}, lazy time: {l_time}\")\n",
    "    return e_origs, e_trads, e_lazys, t_times, l_times\n",
    "\n",
    "print(entropy(np.arange(256)))\n",
    "print(entropy(np.concatenate([np.arange(128), np.arange(128)])))\n",
    "\n",
    "all_e_origs = list()\n",
    "all_e_trads = list()\n",
    "all_e_lazys = list()\n",
    "all_t_times = list()\n",
    "all_l_times = list()\n",
    "d = Dots(50)\n",
    "for i in range(len(entries_)):\n",
    "    d.dot()\n",
    "    e_origs, e_trads, e_lazys, t_times, l_times = check_entropy_whole_pipeline(entries_[i])\n",
    "\n",
    "    all_e_origs.append(e_origs)\n",
    "    all_e_trads.append(e_trads)\n",
    "    all_e_lazys.append(e_lazys)\n",
    "    all_t_times.append(t_times)\n",
    "    all_l_times.append(l_times)\n",
    "d.done()\n",
    "final_e_origs = np.asarray(all_e_origs)\n",
    "final_e_trads = np.asarray(all_e_trads)\n",
    "final_e_lazys = np.asarray(all_e_lazys)\n",
    "final_t_times = np.asarray(all_t_times)\n",
    "final_l_times = np.asarray(all_l_times)\n",
    "\n",
    "print(final_e_origs.shape, final_e_trads.shape, final_e_lazys.shape, final_t_times.shape, final_l_times.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c92796-ef89-4e01-a5e2-acafb38e2033",
   "metadata": {},
   "source": [
    "## Result: Trad vs lazy entropy for the same 8 random patch operations across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53a31e-8cdf-4ab4-aad8-11e53f7739d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_means = np.mean(final_e_trads, axis=1)\n",
    "trad_stds = np.std(final_e_trads, axis=1)\n",
    "lazy_means = np.mean(final_e_lazys, axis=1)\n",
    "lazy_stds = np.std(final_e_lazys, axis=1)\n",
    "\n",
    "print(f\"trad: {trad_means.mean()} +/- {trad_stds.mean()}\")\n",
    "print(f\"lazy: {lazy_means.mean()} +/- {lazy_stds.mean()}\")\n",
    "\n",
    "trad_time = np.mean(final_t_times)\n",
    "lazy_time = np.mean(final_l_times)\n",
    "print(trad_time, lazy_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy_by_vol =np.asarray([\n",
    "#     [-0.5254445716988609, -0.4482721994159677],\n",
    "#     [-0.5053248873702056, -0.4289296268729898],\n",
    "#     [-0.5257666333637427, -0.44651717009131064],\n",
    "#     [-0.4185541374082884, -0.36717499347126215],\n",
    "#     [-0.6223610710233693, -0.5163025613180311],\n",
    "#     [-0.5706122085389952, -0.48348110324083005],\n",
    "#     [-0.5901356124892108, -0.4983918712111845],\n",
    "#     [-0.45334079076036055, -0.38482593263728376],\n",
    "# ])\n",
    "\n",
    "# print(entropy_by_vol[:, 0])\n",
    "# print(entropy_by_vol[:, 1])\n",
    "# print(\"mean:\", entropy_by_vol[:, 0].mean(), entropy_by_vol[:, 1].mean())\n",
    "# print(\"std:\", entropy_by_vol[:, 0].std(), entropy_by_vol[:, 1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4010a2",
   "metadata": {},
   "source": [
    "## Entropy - patch first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def check_entropy_patch_first_pipeline(sample):\n",
    "    # base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "    # sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "    # sample = '001'\n",
    "\n",
    "    # img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "    # lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "    img = nib.load(sample[1][0])\n",
    "    lbl = nib.load(sample[1][1])\n",
    "    \n",
    "    ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "    ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "    ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "    print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline_patch_first()\n",
    "    lp = lazy_pipeline_patch_first(True)\n",
    "\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['image'])\n",
    "    p_label_exts = find_mid_label(ddict['image'])\n",
    "    # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "    p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['image'].shape[1], int(100 * 240 / 192)))\n",
    "    p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['image'].shape[2], int(100 * 240 / 192)))\n",
    "    # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "    num_samples = 8\n",
    "    print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    vols = []\n",
    "    results = []\n",
    "    t_time = 0\n",
    "    l_time = 0\n",
    "    for i in range(num_samples):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_time += time.time() - t_start\n",
    "        # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "        t_label_exts = find_mid_label(t_out['image'])\n",
    "        # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "        t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['image'].shape[1], 100))\n",
    "        t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['image'].shape[2], 100))\n",
    "        # print(\"extents:\", t_slice_x, t_slice_y)\n",
    "        # print(t_first_z, t_last_z, t_mid_slice)\n",
    "\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_time += time.time() - l_start\n",
    "        # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "        l_label_exts = find_mid_label(l_out['image'])\n",
    "        # print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "        l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['image'].shape[1], 100))\n",
    "        l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['image'].shape[2], 100))\n",
    "        # print(\"extents:\", l_slice_x, l_slice_y)\n",
    "        # print(l_first_z, l_last_z, l_mid_slice)\n",
    "    \n",
    "        vols.extend([ddict['image'][0, ...],\n",
    "                     t_out['image'][1, ...],\n",
    "                     l_out['image'][2, ...]])\n",
    "\n",
    "        results.extend([ddict['image'][0, ..., pre_mid_slice],\n",
    "                        t_out['image'][0, ..., t_label_exts[2][2]],\n",
    "                        l_out['image'][0, ..., l_label_exts[2][2]]])\n",
    "        \n",
    "    for i_r in range(8):\n",
    "        ovol = vols[i_r * 3]\n",
    "        tvol = vols[i_r * 3 + 1]\n",
    "        lvol = vols[i_r * 3 + 2]\n",
    "        print(\"ovol:\", entropy(ovol),\n",
    "              \"tvol:\", entropy(tvol),\n",
    "              \"lvol:\", entropy(lvol))\n",
    "            \n",
    "\n",
    "    print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    plot_datas(results, 3, tight=True, size=10)\n",
    "    display_images['forward_images_patch'] = copy.deepcopy(results[6:9])\n",
    "    \n",
    "check_entropy_patch_first_pipeline(entries_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e216d1-34c5-41dd-ae0a-4163c061e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def check_entropy_patch_first_pipeline(sample):\n",
    "\n",
    "    img, lbl = load_sample(sample)\n",
    "    img = img[0:1, ...]\n",
    "    ddict = {'image': img, 'label': lbl}\n",
    "\n",
    "    tp = trad_pipeline_patch_first()\n",
    "    lp = lazy_pipeline_patch_first(True)\n",
    "\n",
    "    num_samples = 8\n",
    "    vols = []\n",
    "    t_times = []\n",
    "    l_times = []\n",
    "    for i in range(num_samples):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_times.append(time.time() - t_start)\n",
    "\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_times.append(time.time() - l_start)\n",
    "    \n",
    "        vols.extend([ddict['image'][0, ...],\n",
    "                     t_out['image'][0, ...],\n",
    "                     l_out['image'][0, ...]])\n",
    "\n",
    "    e_origs = list()\n",
    "    e_trads = list()\n",
    "    e_lazys = list()\n",
    "    for i_r in range(8):\n",
    "        ovol = vols[i_r * 3]\n",
    "        tvol = vols[i_r * 3 + 1]\n",
    "        lvol = vols[i_r * 3 + 2]\n",
    "        e_orig = entropy(ovol)\n",
    "        e_trad = entropy(tvol)\n",
    "        e_lazy = entropy(lvol)\n",
    "        e_origs.append(e_orig)\n",
    "        e_trads.append(e_trad)\n",
    "        e_lazys.append(e_lazy)\n",
    "            \n",
    "\n",
    "    # print(f\"trad time: {sum(t_times) / len(t_times)}, \"\n",
    "    #       f\"lazy time: {sum(l_times) / len(l_times)}\")\n",
    "    return e_origs, e_trads, e_lazys, t_times, l_times\n",
    "\n",
    "all_e_origs = list()\n",
    "all_e_trads = list()\n",
    "all_e_lazys = list()\n",
    "all_t_times = list()\n",
    "all_l_times = list()\n",
    "d = Dots(50)\n",
    "for i in range(len(entries_)):\n",
    "    d.dot()\n",
    "    e_origs, e_trads, e_lazys, t_times, l_times = check_entropy_patch_first_pipeline(entries_[i])\n",
    "\n",
    "    all_e_origs.append(e_origs)\n",
    "    all_e_trads.append(e_trads)\n",
    "    all_e_lazys.append(e_lazys)\n",
    "    all_t_times.append(t_times)\n",
    "    all_l_times.append(l_times)\n",
    "d.done()\n",
    "final_e_origs = np.asarray(all_e_origs)\n",
    "final_e_trads = np.asarray(all_e_trads)\n",
    "final_e_lazys = np.asarray(all_e_lazys)\n",
    "final_t_times = np.asarray(all_t_times)\n",
    "final_l_times = np.asarray(all_l_times)\n",
    "\n",
    "print(final_e_origs.shape, final_e_trads.shape, final_e_lazys.shape, final_t_times.shape, final_l_times.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20201a-4b19-4db0-a16d-cd42f4424783",
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_means = np.mean(final_e_trads, axis=1)\n",
    "trad_stds = np.std(final_e_trads, axis=1)\n",
    "lazy_means = np.mean(final_e_lazys, axis=1)\n",
    "lazy_stds = np.std(final_e_lazys, axis=1)\n",
    "\n",
    "print(f\"trad: {trad_means.mean()} +/- {trad_stds.mean()}\")\n",
    "print(f\"lazy: {lazy_means.mean()} +/- {lazy_stds.mean()}\")\n",
    "\n",
    "trad_time = np.mean(final_t_times)\n",
    "lazy_time = np.mean(final_l_times)\n",
    "print(trad_time, lazy_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_by_vol =np.asarray([\n",
    "    [-0.6474312370041032, -0.5746644873304773],\n",
    "    [-0.5820207582029828, -0.5154538747569736],\n",
    "    [-0.6303136122149402, -0.5550618036447265],\n",
    "    [-0.5225025523734912, -0.45886897465822146],\n",
    "    [-0.7313230393674943, -0.6375291263882021],\n",
    "    [-0.6009636467276522, -0.5386724596584971],\n",
    "    [-0.658219893839086, -0.5855626119150623],\n",
    "    [-0.5656265423842755, -0.481065145373282],\n",
    "])\n",
    "\n",
    "print(entropy_by_vol[:, 0])\n",
    "print(entropy_by_vol[:, 1])\n",
    "print(\"mean:\", entropy_by_vol[:, 0].mean(), entropy_by_vol[:, 1].mean())\n",
    "print(\"std:\", entropy_by_vol[:, 0].std(), entropy_by_vol[:, 1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e254aae",
   "metadata": {},
   "source": [
    "## Entropy - patch last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd633d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def check_entropy_patch_last_pipeline():\n",
    "    base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "    sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "    sample = '001'\n",
    "\n",
    "    img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "    lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "    ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "    ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "    ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "    # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline_patch_last()\n",
    "    lp = lazy_pipeline_patch_last(True)\n",
    "\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['image'])\n",
    "    p_label_exts = find_mid_label(ddict['image'])\n",
    "    # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "    p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['image'].shape[1], int(100 * 240 / 192)))\n",
    "    p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['image'].shape[2], int(100 * 240 / 192)))\n",
    "    # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "    num_samples = 8\n",
    "    print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    vols = []\n",
    "    results = []\n",
    "    t_time = 0\n",
    "    l_time = 0\n",
    "    for i in range(num_samples):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_time += time.time() - t_start\n",
    "        # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "        t_label_exts = find_mid_label(t_out['image'])\n",
    "        print(\"t_label_exts:\", t_label_exts)\n",
    "        # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "        t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['image'].shape[1], 100))\n",
    "        t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['image'].shape[2], 100))\n",
    "        print(\"extents:\", t_slice_x, t_slice_y)\n",
    "        # print(t_first_z, t_last_z, t_mid_slice)\n",
    "\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_time += time.time() - l_start\n",
    "        # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "        print(\"l_out:\", l_out['image'].shape)\n",
    "        l_label_exts = find_mid_label(l_out['image'])\n",
    "        print(\"l_label_exts:\", l_label_exts)\n",
    "        # print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "        l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['image'].shape[1], 100))\n",
    "        l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['image'].shape[2], 100))\n",
    "        print(\"extents:\", l_slice_x, l_slice_y)\n",
    "        # print(l_first_z, l_last_z, l_mid_slice)\n",
    "    \n",
    "        vols.extend([ddict['image'][0, ...],\n",
    "                     t_out['image'][1, ...],\n",
    "                     l_out['image'][2, ...]])\n",
    "\n",
    "        results.extend([ddict['image'][0, ..., p_label_exts[2][2]],\n",
    "                        t_out['image'][0, ..., t_label_exts[2][2]],\n",
    "                        l_out['image'][0, ..., l_label_exts[2][2]]])\n",
    "        \n",
    "    for i_r in range(8):\n",
    "        ovol = vols[i_r * 3]\n",
    "        tvol = vols[i_r * 3 + 1]\n",
    "        lvol = vols[i_r * 3 + 2]\n",
    "        print(\"ovol:\", entropy(ovol),\n",
    "              \"tvol:\", entropy(tvol),\n",
    "              \"lvol:\", entropy(lvol))\n",
    "            \n",
    "\n",
    "    print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    plot_datas(results, 3, tight=True, size=10)\n",
    "    \n",
    "check_entropy_patch_last_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730dc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_by_vol =np.asarray([\n",
    "    [-0.6474312370041032, -0.5746644873304773],\n",
    "    [-0.5820207582029828, -0.5154538747569736],\n",
    "    [-0.6303136122149402, -0.5550618036447265],\n",
    "    [-0.5225025523734912, -0.45886897465822146],\n",
    "    [-0.7313230393674943, -0.6375291263882021],\n",
    "    [-0.6009636467276522, -0.5386724596584971],\n",
    "    [-0.658219893839086, -0.5855626119150623],\n",
    "    [-0.5656265423842755, -0.481065145373282],\n",
    "])\n",
    "\n",
    "print(entropy_by_vol[:, 0])\n",
    "print(entropy_by_vol[:, 1])\n",
    "print(\"mean:\", entropy_by_vol[:, 0].mean(), entropy_by_vol[:, 1].mean())\n",
    "print(\"std:\", entropy_by_vol[:, 0].std(), entropy_by_vol[:, 1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf3d93",
   "metadata": {},
   "source": [
    "# Entropy - all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "\n",
    "# def check_entropy_whole_pipeline():\n",
    "#     base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "#     sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "#     sample = '001'\n",
    "\n",
    "#     img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "#     lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "#     ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "#     ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "#     ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "#     # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "#     tp = trad_pipeline()\n",
    "#     lp = lazy_pipeline(True)\n",
    "\n",
    "#     num_samples = 8\n",
    "#     results = []\n",
    "#     for i in range(num_samples):\n",
    "#         t_out = tp(ddict)\n",
    "#         l_out = lp(ddict)\n",
    "#         results.append([\n",
    "#             entropy(ddict['image']),\n",
    "#             entropy(t_out['image']),\n",
    "#             entropy(l_out['image'])\n",
    "#         ])\n",
    "        \n",
    "#     results = np.asarray(results)\n",
    "#     print(results.shape)\n",
    "        \n",
    "# check_entropy_whole_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ceb46",
   "metadata": {},
   "source": [
    "## Whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93171245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "\n",
    "# def check_whole_pipeline_forward():\n",
    "#     base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "#     sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "#     sample = '001'\n",
    "\n",
    "#     img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "#     lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "#     ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "#     ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "#     ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "#     # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "#     tp = trad_pipeline()\n",
    "#     lp = lazy_pipeline(True)\n",
    "\n",
    "#     pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "#     p_label_exts = find_mid_label(ddict['label'])\n",
    "#     # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "#     p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['label'].shape[1], int(100 * 240 / 192)))\n",
    "#     p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['label'].shape[2], int(100 * 240 / 192)))\n",
    "#     # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "#     print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "#     results = []\n",
    "#     t_time = 0\n",
    "#     l_time = 0\n",
    "#     for i in range(8):\n",
    "#         t_start = time.time()\n",
    "#         t_out = tp(ddict)\n",
    "#         t_time += time.time() - t_start\n",
    "#         # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "#         t_label_exts = find_mid_label(t_out['label'])\n",
    "#         # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "#         t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['label'].shape[1], 100))\n",
    "#         t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['label'].shape[2], 100))\n",
    "#         # print(\"extents:\", t_slice_x, t_slice_y)\n",
    "#         # print(t_first_z, t_last_z, t_mid_slice)\n",
    "\n",
    "#         l_start = time.time()\n",
    "#         l_out = lp(ddict)\n",
    "#         l_time += time.time() - l_start\n",
    "#         # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "#         l_label_exts = find_mid_label(l_out['label'])\n",
    "#         # print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "#         l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['label'].shape[1], 100))\n",
    "#         l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['label'].shape[2], 100))\n",
    "#         # print(\"extents:\", l_slice_x, l_slice_y)\n",
    "#         # print(l_first_z, l_last_z, l_mid_slice)\n",
    "    \n",
    "#         results.extend([ddict['label'][0, p_slice_x, p_slice_y, pre_mid_slice],\n",
    "#                         t_out['label'][0, t_slice_x, t_slice_y, t_label_exts[2][2]],\n",
    "#                         l_out['label'][0, l_slice_x, l_slice_y, l_label_exts[2][2]]])\n",
    "\n",
    "#     print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    \n",
    "#     display_images['forward_pass_whole'] = copy.deepcopy(results[18:21])\n",
    "#     # plot_datas(results, 6)\n",
    "#     plot_datas(results, 3, tight=True)\n",
    "    \n",
    "# check_whole_pipeline_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2ae36",
   "metadata": {},
   "source": [
    "## Patch first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaeb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def check_patch_first_pipeline_forward():\n",
    "    base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "    sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "    sample = '001'\n",
    "    \n",
    "    iterations = 4\n",
    "\n",
    "    img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "    lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "    ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "    ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "    ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "    # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline_patch_first()\n",
    "    lp = lazy_pipeline_patch_first(True)\n",
    "\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "    p_label_exts = find_mid_label(ddict['label'])\n",
    "    # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "    p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['label'].shape[1], int(100 * 240 / 192)))\n",
    "    p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['label'].shape[2], int(100 * 240 / 192)))\n",
    "    # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "#     pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "#     print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    results = []\n",
    "    t_time = 0\n",
    "    l_time = 0\n",
    "    for i in range(iterations):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_time += time.time() - t_start\n",
    "        # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "        t_label_exts = find_mid_label(t_out['label'])\n",
    "        # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "        t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['label'].shape[1], 100))\n",
    "        t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['label'].shape[2], 100))\n",
    "        # print(\"extents:\", t_slice_x, t_slice_y)\n",
    "        # print(t_first_z, t_last_z, t_mid_slice)\n",
    "#         t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "#         print(t_first_z, t_last_z, t_mid_slice)\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_time += time.time() - l_start\n",
    "        # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "        l_label_exts = find_mid_label(l_out['label'])\n",
    "        # print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "        l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['label'].shape[1], 100))\n",
    "        l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['label'].shape[2], 100))\n",
    "        # print(\"extents:\", l_slice_x, l_slice_y)\n",
    "        # print(l_first_z, l_last_z, l_mid_slice)\n",
    "#         l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "#         print(l_first_z, l_last_z, l_mid_slice)\n",
    "\n",
    "        results.extend([ddict['label'][0, p_slice_x, p_slice_y, pre_mid_slice],\n",
    "                        t_out['label'][0, t_slice_x, t_slice_y, t_label_exts[2][2]],\n",
    "                        l_out['label'][0, l_slice_x, l_slice_y, l_label_exts[2][2]]])\n",
    "    print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    # plot_datas(results, 6)\n",
    "    \n",
    "    display_images['forward_pass_patch'] = copy.deepcopy(results[6:9])\n",
    "\n",
    "    plot_datas(results, 3, tight=True)\n",
    "    \n",
    "check_patch_first_pipeline_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c892aa",
   "metadata": {},
   "source": [
    "## Patch last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def check_patch_first_pipeline_forward():\n",
    "    base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "    sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "    sample = '001'\n",
    "    \n",
    "    iterations = 4\n",
    "\n",
    "    img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "    lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "    ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "    ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "    ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "    # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline_patch_last()\n",
    "    lp = lazy_pipeline_patch_last(True)\n",
    "\n",
    "#     pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "#     p_label_exts = find_mid_label(ddict['label'])\n",
    "#     # print(\"mid-label:\", p_label_exts, tuple(p[1] - p[0] for p in p_label_exts))\n",
    "#     p_slice_x = slice(*sanitized_range_from_extents(p_label_exts[0][2], ddict['label'].shape[1], int(100 * 240 / 192)))\n",
    "#     p_slice_y = slice(*sanitized_range_from_extents(p_label_exts[1][2], ddict['label'].shape[2], int(100 * 240 / 192)))\n",
    "#     # print(\"extents:\", p_slice_x, p_slice_y)\n",
    "\n",
    "# #     pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "# #     print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "#     results = []\n",
    "#     t_time = 0\n",
    "#     l_time = 0\n",
    "#     for i in range(iterations):\n",
    "#         t_start = time.time()\n",
    "#         t_out = tp(ddict)\n",
    "#         t_time += time.time() - t_start\n",
    "#         # t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "#         t_label_exts = find_mid_label(t_out['label'])\n",
    "#         print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "#         t_slice_x = slice(*sanitized_range_from_extents(t_label_exts[0][2], t_out['label'].shape[1], 100))\n",
    "#         t_slice_y = slice(*sanitized_range_from_extents(t_label_exts[1][2], t_out['label'].shape[2], 100))\n",
    "#         # print(\"extents:\", t_slice_x, t_slice_y)\n",
    "#         # print(t_first_z, t_last_z, t_mid_slice)\n",
    "# #         t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "# #         print(t_first_z, t_last_z, t_mid_slice)\n",
    "#         l_start = time.time()\n",
    "#         l_out = lp(ddict)\n",
    "#         l_time += time.time() - l_start\n",
    "#         # l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "#         l_label_exts = find_mid_label(l_out['label'])\n",
    "#         print(\"mid-label:\", l_label_exts, tuple(l[1] - l[0] for l in l_label_exts))\n",
    "#         l_slice_x = slice(*sanitized_range_from_extents(l_label_exts[0][2], l_out['label'].shape[1], 100))\n",
    "#         l_slice_y = slice(*sanitized_range_from_extents(l_label_exts[1][2], l_out['label'].shape[2], 100))\n",
    "#         # print(\"extents:\", l_slice_x, l_slice_y)\n",
    "#         # print(l_first_z, l_last_z, l_mid_slice)\n",
    "# #         l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "# #         print(l_first_z, l_last_z, l_mid_slice)\n",
    "\n",
    "#         results.extend([ddict['label'][0, p_slice_x, p_slice_y, pre_mid_slice],\n",
    "#                         t_out['label'][0, t_slice_x, t_slice_y, t_label_exts[2][2]],\n",
    "#                         l_out['label'][0, l_slice_x, l_slice_y, l_label_exts[2][2]]])\n",
    "\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "    print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    results = []\n",
    "    t_time = 0\n",
    "    l_time = 0\n",
    "    for i in range(iterations):\n",
    "        t_start = time.time()\n",
    "        t_out = tp(ddict)\n",
    "        t_time += time.time() - t_start\n",
    "        print(t_out['label'].shape)\n",
    "        t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "        print(\"t:\", t_first_z, t_last_z, t_mid_slice)\n",
    "        l_start = time.time()\n",
    "        l_out = lp(ddict)\n",
    "        l_time += time.time() - l_start\n",
    "        l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "        print(\"l:\", l_first_z, l_last_z, l_mid_slice)\n",
    "\n",
    "    #     results.extend([ddict['image'][0, ..., pre_mid_slice], ddict['label'][0, ..., pre_mid_slice],\n",
    "    #                     t_out['image'][0, ..., post_mid_slice], t_out['label'][0, ..., post_mid_slice],\n",
    "    #                     l_out['image'][0, ..., post_mid_slice], l_out['label'][0, ..., post_mid_slice]])\n",
    "        results.extend([ddict['label'][0, ..., pre_mid_slice],\n",
    "                        t_out['label'][0, ..., t_mid_slice],\n",
    "                        l_out['label'][0, ..., l_mid_slice]])\n",
    "    print(f\"trad time: {t_time}, lazy time: {l_time}\")\n",
    "    # plot_datas(results, 6)\n",
    "    plot_datas(results, 3, tight=True)\n",
    "    \n",
    "check_patch_first_pipeline_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1d991",
   "metadata": {},
   "source": [
    "# Roundtrip experiment with issues - probably caused by not deep copying the tensor, although that really ought not be an issue (I think it is a MONAI issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundtrip_experiment():\n",
    "    base_dir = '/home/ben/data/preprocessed/Task01_BrainTumour/orig'\n",
    "    sample_str = 'BRATS_{}_{}.nii.gz'\n",
    "    sample = '001'\n",
    "\n",
    "    img = nib.load(os.path.join(base_dir, sample_str.format(sample, 'image')))\n",
    "    lbl = nib.load(os.path.join(base_dir, sample_str.format(sample, 'label')))\n",
    "\n",
    "    ddict = {'image': img.get_fdata(), 'label': lbl.get_fdata()}\n",
    "\n",
    "    ddict['image'] = np.transpose(ddict['image'], axes=(3, 0, 1, 2))\n",
    "    ddict['label'] = np.expand_dims(ddict['label'], axis=0)\n",
    "\n",
    "    # print(ddict['image'].shape, ddict['label'].shape)\n",
    "\n",
    "    tp = trad_pipeline()\n",
    "    lp = lazy_pipeline(True)\n",
    "    # before = []\n",
    "    # after = []\n",
    "    print(\"tp:\", tp)\n",
    "    print(\"lp:\", lp)\n",
    "    \n",
    "    tinverter = Invert(transform=tp, nearest_interp=True, device=\"cpu\", post_func=torch.as_tensor)\n",
    "    linverter = Invert(transform=lp, nearest_interp=True, device=\"cpu\", post_func=torch.as_tensor)\n",
    "    pre_first_z, pre_last_z, pre_mid_slice = find_mid_label_z(ddict['label'])\n",
    "    print(pre_first_z, pre_last_z, pre_mid_slice)\n",
    "    # pre_mid_slice=77\n",
    "    # post_mid_slice=36\n",
    "    results = []\n",
    "    for i in range(8):\n",
    "        t_out = tp(ddict)\n",
    "        t_inv = tinverter(t_out)\n",
    "#         t_first_z, t_last_z, t_mid_slice = find_mid_label_z(t_out['label'])\n",
    "#         print(t_first_z, t_last_z, t_mid_slice)\n",
    "        l_out = lp(ddict)\n",
    "        l_inv = linverter(l_out)\n",
    "#         l_first_z, l_last_z, l_mid_slice = find_mid_label_z(l_out['label'])\n",
    "#         print(l_first_z, l_last_z, l_mid_slice)\n",
    "\n",
    "    #     results.extend([ddict['image'][0, ..., pre_mid_slice], ddict['label'][0, ..., pre_mid_slice],\n",
    "    #                     t_out['image'][0, ..., post_mid_slice], t_out['label'][0, ..., post_mid_slice],\n",
    "    #                     l_out['image'][0, ..., post_mid_slice], l_out['label'][0, ..., post_mid_slice]])\n",
    "        results.extend([ddict['image'][0, ..., pre_mid_slice],\n",
    "                        t_inv['image'][0, ..., pre_mid_slice],\n",
    "                        l_inv['image'][0, ..., pre_mid_slice]])\n",
    "\n",
    "    # plot_datas(results, 6)\n",
    "    plot_datas(results, 3, tight=True)\n",
    "    \n",
    "roundtrip_experiment()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ea20",
   "metadata": {},
   "source": [
    "# RandGridDistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rand_grid_distortion():\n",
    "    data = get_img((64, 64))\n",
    "    hival = data.max()\n",
    "    data[0,7:9,7:9] = hival + 64\n",
    "    data[0,15:17,:] = hival + 128\n",
    "    data[0,0,:] = hival + 192\n",
    "    data[0,:,0] = hival + 256\n",
    "    print(data.shape)\n",
    "    \n",
    "    r1 = RandGridDistortion(9, 1.0, (-0.1, 0.1), padding_mode=\"zeros\")\n",
    "    result1 = r1(data)\n",
    "    \n",
    "    r2 = Rand2DElastic((4, 4), (-0.1, 0.1), 1.0, padding_mode=\"zeros\")\n",
    "    result2 = r2(data)\n",
    "    \n",
    "    plot_datas([data, result1, result2])\n",
    "\n",
    "do_rand_grid_distortion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f217307",
   "metadata": {},
   "source": [
    "# Inversion test - whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57319b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_invert(labels, verbose=False):\n",
    "    import sys\n",
    "    from copy import deepcopy\n",
    "    from monai.utils import set_determinism\n",
    "    # from tests.utils import assert_allclose, make_nifti_image    \n",
    "    from monai.data import DataLoader, Dataset, MetaTensor, create_test_image_3d, decollate_batch\n",
    "    from monai.transforms import (\n",
    "        Compose,\n",
    "        EnsureChannelFirst,\n",
    "        Invert,\n",
    "        LoadImage,\n",
    "    )\n",
    "\n",
    "    mode = 'nearest'\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    num_rows = len(labels)\n",
    "    if verbose:\n",
    "        print(labels)\n",
    "    rows_to_display = 8\n",
    "    lazy = True\n",
    "    base_images = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    transform_old = trad_pipeline_label_only()\n",
    "    transform_new = lazy_pipeline_label_only()\n",
    "    \n",
    "    # results = [None for _ in range(num_rows * 3)]\n",
    "    results = [None for _ in range(rows_to_display * 3)]\n",
    "\n",
    "    dl = DiceLoss(reduction=\"none\")\n",
    "    trad_losses = list()\n",
    "    lazy_losses = list()\n",
    "\n",
    "    for i_tx, tx in enumerate([transform_old, transform_new]):\n",
    "        if i_tx == 0:\n",
    "            print(\"trad pass\")\n",
    "        else:\n",
    "            print(\"lazy pass\")\n",
    "\n",
    "        losses = trad_losses if i_tx == 0 else lazy_losses\n",
    "        # num workers = 0 for mac or gpu transforms\n",
    "        num_workers = 0 if sys.platform != \"linux\" or torch.cuda.is_available() else 2\n",
    "        # base_dataset = Dataset(data, transform=base_images)\n",
    "        base_dataset = Dataset(labels, transform=base_images)\n",
    "        base_loader = DataLoader(base_dataset, suppress_rng=True, num_workers=num_workers, batch_size=1)\n",
    "\n",
    "        # dataset = Dataset(data, transform=tx)\n",
    "        dataset = Dataset(labels, transform=tx)\n",
    "        loader = DataLoader(dataset, suppress_rng=True, num_workers=num_workers, batch_size=1)\n",
    "        inverter = Invert(transform=tx, nearest_interp=True, device=\"cpu\", post_func=torch.as_tensor)\n",
    "\n",
    "        dots = Dots(50)\n",
    "        for i_d, (d_orig, d_full) in enumerate(zip(base_loader, loader)):\n",
    "            if not verbose:\n",
    "                dots.dot()\n",
    "            assert(len(d_orig) == 1 and len(d_full) == 1)\n",
    "            # only generating one sample so just dereference it\n",
    "            d_orig = decollate_batch(d_orig)[0]\n",
    "            d_full = decollate_batch(d_full)[0]\n",
    "            # print(\"shapes:\", d_orig.shape, d_full.shape)\n",
    "            if verbose:\n",
    "                print(d_orig.shape)\n",
    "            if i_tx == 0:\n",
    "                if i_d < rows_to_display:\n",
    "                    results[i_d * 3] = d_orig\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"sample {i_d}:\", np.unique(d_full, return_counts=True))\n",
    "                print(np.unique(d_full, return_counts=True))\n",
    "            d_full_copy = deepcopy(d_full)\n",
    "            d_roundtrip = inverter(d_full_copy)\n",
    "            if verbose:\n",
    "                print(d_orig.shape, d_roundtrip.shape)\n",
    "            if i_d < rows_to_display:\n",
    "                results[i_d * 3 + i_tx + 1] = d_roundtrip\n",
    "\n",
    "            if verbose:\n",
    "                print(\"d_orig hist:\", d_orig.unique(return_counts=True))\n",
    "                print(\"d_roundtrip hist:\", d_roundtrip.unique(return_counts=True))\n",
    "            d_orig_1h = torch.nn.functional.one_hot(d_orig.long(), num_classes=4).permute(0, 4, 1, 2, 3)\n",
    "            d_roundtrip_1h = torch.nn.functional.one_hot(d_roundtrip.long(), num_classes=4).permute(0, 4, 1, 2, 3)\n",
    "            if verbose:\n",
    "                print(\"orig hist:\", d_orig_1h.unique(return_counts=True))\n",
    "                print(\"roundtrip_hist:\", d_roundtrip_1h.unique(return_counts=True))\n",
    "                print(\"loss arg shapes:\", d_orig_1h.shape, d_roundtrip_1h.shape)\n",
    "            loss = dl(d_orig_1h, d_roundtrip_1h)\n",
    "            if verbose:\n",
    "                print(\"loss shape:\", loss.shape)\n",
    "            loss = loss.mean(dim=(2, 3, 4)).detach().cpu().numpy()\n",
    "            if verbose:\n",
    "                print(\"loss:\", loss)\n",
    "            losses.append(1 - loss)\n",
    "\n",
    "                # # old buggy score calc - loss shape is [4, 240, 1, 1]\n",
    "                # d_orig_1h = torch.squeeze(torch.nn.functional.one_hot(d_orig.long()), 0).permute(3, 0, 1, 2)\n",
    "                # d_roundtrip_1h = torch.squeeze(torch.nn.functional.one_hot(d_roundtrip.long()), 0).permute(3, 0, 1, 2)\n",
    "                # print(\"loss arg shapes:\", d_orig_1h.shape, d_roundtrip_1h.shape)\n",
    "                # loss = dl(d_orig_1h, d_roundtrip_1h)\n",
    "                # print(\"loss shape:\", loss.shape)\n",
    "                # loss = loss.mean(dim=(1, 2, 3)).detach().cpu().numpy()\n",
    "                # print(\"loss:\", loss)\n",
    "                # losses.append(1 - loss)\n",
    "        if not verbose:\n",
    "            dots.done()\n",
    "\n",
    "        reverted = d_roundtrip.detach().cpu().numpy().astype(np.int32)\n",
    "        original = LoadImage(image_only=True)(labels[-1])\n",
    "        n_good = np.sum(np.isclose(reverted, original.numpy(), atol=1e-3))\n",
    "        reverted_name = d_roundtrip.meta[\"filename_or_obj\"]\n",
    "        original_name = original.meta[\"filename_or_obj\"]\n",
    "        print(\"invert diff\", reverted.size - n_good)\n",
    "        set_determinism(seed=None)\n",
    "\n",
    "    # for tl, ll in zip(trad_losses, lazy_losses):\n",
    "    #     print(tl, tl.mean(), ll, ll.mean())\n",
    "\n",
    "    clipped_results = list()\n",
    "    for r in results:\n",
    "        r_label_exts = find_mid_label(r)\n",
    "        # print(\"mid-label:\", t_label_exts, tuple(t[1] - t[0] for t in t_label_exts))\n",
    "        r_slice_x = slice(*sanitized_range_from_extents(r_label_exts[0][2], r.shape[1], 120))\n",
    "        r_slice_y = slice(*sanitized_range_from_extents(r_label_exts[1][2], r.shape[2], 120))\n",
    "\n",
    "        clipped_results.append(r[0, r_slice_x, r_slice_y, r_label_exts[2][2]])\n",
    "\n",
    "    display_images['round_trip_whole'] = copy.deepcopy(clipped_results[21:24])\n",
    "    plot_datas(clipped_results, 3, tight=True)\n",
    "\n",
    "    return trad_losses, lazy_losses\n",
    "\n",
    "print(entries_[0])\n",
    "trad_rt_losses_, lazy_rt_losses_ = test_invert([e[1][1] for e in entries_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f178c03-00c6-4309-a8aa-5d3165dabfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trad_rt_means = np.concatenate(trad_rt_losses_).mean(axis=1)\n",
    "# lazy_rt_means = np.concatenate(lazy_rt_losses_).mean(axis=1)\n",
    "trad_rt_losses_np = np.concatenate(trad_rt_losses_)\n",
    "lazy_rt_losses_np = np.concatenate(lazy_rt_losses_)\n",
    "trad_rt_means = trad_rt_losses_np.mean(axis=1)\n",
    "lazy_rt_means = lazy_rt_losses_np.mean(axis=1)\n",
    "# print(trad_rt_means)\n",
    "# print(lazy_rt_means)\n",
    "print(f\"trad - min: {trad_rt_means.min()}, max: {trad_rt_means.max()}, mean: {trad_rt_means.mean()}, std: {trad_rt_means.std()}\")\n",
    "print(f\"lazy - min: {lazy_rt_means.min()}, max: {lazy_rt_means.max()}, mean: {lazy_rt_means.mean()}, std: {lazy_rt_means.std()}\")\n",
    "\n",
    "for i in range(4):\n",
    "    trad_rt_class = trad_rt_losses_np[..., i]\n",
    "    lazy_rt_class = lazy_rt_losses_np[..., i]\n",
    "    print(trad_rt_class.shape)\n",
    "    print(f\"trad {i} - count near zero: {np.count_nonzero(trad_rt_class < 0.01)}\")\n",
    "    print(f\"lazy {i} - count near zero: {np.count_nonzero(lazy_rt_class < 0.01)}\")\n",
    "    print(f\"trad {i} - min: {trad_rt_class.min()}, max: {trad_rt_class.max()}, mean: {trad_rt_class.mean()}, std: {trad_rt_class.std()}\")\n",
    "    print(f\"lazy {i} - min: {lazy_rt_class.min()}, max: {lazy_rt_class.max()}, mean: {lazy_rt_class.mean()}, std: {lazy_rt_class.std()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ee1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are wrong, see\n",
    "trad_class_losses = np.asarray([\n",
    "    [0.9976, 0.8967, 0.9199, 0.9024],\n",
    "    [0.9985, 0.9153, 0.8667, 0.9218],\n",
    "    [0.9975, 0.8710, 0.8469, 0.9291],\n",
    "    [0.9988, 0.8790, 0.9178, 0.9098],\n",
    "    [0.9994, 0.9362, 0.9530, 0.9339],\n",
    "    [0.9968, 0.8567, 0.8951, 0.8981],\n",
    "    [0.9981, 0.8157, 0.8726, 0.8884],\n",
    "    [0.9977, 0.8998, 0.8801, 0.9043]\n",
    "])\n",
    "\n",
    "lazy_class_losses = np.asarray([\n",
    "    [0.9996, 0.9714, 0.9692, 0.9769],\n",
    "    [0.9997, 0.9795, 0.9274, 0.9832],\n",
    "    [0.9992, 0.9609, 0.9249, 0.9806],\n",
    "    [0.9996, 0.9470, 0.9736, 0.9507],\n",
    "    [0.9997, 0.9692, 0.9736, 0.9690],\n",
    "    [0.9995, 0.9695, 0.9692, 0.9774],\n",
    "    [0.9997, 0.9547, 0.9657, 0.9825],\n",
    "    [0.9992, 0.9564, 0.9441, 0.9612]\n",
    "])\n",
    "\n",
    "print(trad_class_losses.shape)\n",
    "print(lazy_class_losses.shape)\n",
    "print(trad_class_losses.mean(axis=0), trad_class_losses.std(axis=0))\n",
    "print(lazy_class_losses.mean(axis=0), trad_class_losses.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc9914",
   "metadata": {},
   "source": [
    "## Earlier inversion test - what is it for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644413c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_invert():\n",
    "    import sys\n",
    "    from copy import deepcopy\n",
    "    from monai.utils import set_determinism\n",
    "    # from tests.utils import assert_allclose, make_nifti_image    \n",
    "    from monai.data import DataLoader, Dataset, MetaTensor, create_test_image_3d, decollate_batch\n",
    "    from monai.transforms import (\n",
    "        CastToType,\n",
    "        Compose,\n",
    "        EnsureChannelFirst,\n",
    "        Invert,\n",
    "        LoadImage,\n",
    "        Orientation,\n",
    "        RandAffine,\n",
    "        RandAxisFlip,\n",
    "        RandFlip,\n",
    "        RandRotate,\n",
    "        RandRotate90,\n",
    "        RandZoom,\n",
    "        ResizeWithPadOrCrop,\n",
    "        Spacing,\n",
    "    )\n",
    "\n",
    "    num_rows = 4\n",
    "\n",
    "    mode = 'nearest'\n",
    "    set_determinism(seed=0)\n",
    "    # im_fname = make_nifti_image(create_test_image_3d(101, 100, 107, noise_max=100)[1])  # label image, discrete\n",
    "#     data = [im_fname for _ in range(12)]\n",
    "\n",
    "    data = ['/home/ben/data/preprocessed/Task01_BrainTumour/orig/BRATS_001_label.nii.gz',\n",
    "            '/home/ben/data/preprocessed/Task01_BrainTumour/orig/BRATS_002_label.nii.gz',\n",
    "            '/home/ben/data/preprocessed/Task01_BrainTumour/orig/BRATS_003_label.nii.gz',\n",
    "            '/home/ben/data/preprocessed/Task01_BrainTumour/orig/BRATS_004_label.nii.gz']\n",
    "\n",
    "    print(data)\n",
    "    lazy = True\n",
    "    base_images = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "        ]\n",
    "    )\n",
    "    transform_old = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            # Orientation(\"RPS\"),\n",
    "            old.Spacing(pixdim=(1.2, 1.01, 0.9), mode=mode, dtype=np.float32),\n",
    "            old.Flip(spatial_axis=[1, 2]),\n",
    "            old.Rotate90(spatial_axes=(1, 2)),\n",
    "            old.Zoom(zoom=0.75, keep_size=True),\n",
    "            old.Rotate(angle=(np.pi, 0, 0), mode=mode, align_corners=True, dtype=np.float64),\n",
    "            # RandAffine(prob=0.5, rotate_range=np.pi, mode=\"nearest\"),\n",
    "            # ResizeWithPadOrCrop(100),\n",
    "            CastToType(dtype=torch.uint8),\n",
    "        ]\n",
    "    )\n",
    "    transform_new = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            # Orientation(\"RPS\"),\n",
    "            Spacing(pixdim=(1.2, 1.01, 0.9), mode=mode, dtype=np.float32, lazy_evaluation=lazy),\n",
    "            Flip(spatial_axis=[1, 2], lazy_evaluation=lazy),\n",
    "            Rotate90(spatial_axes=(1, 2), lazy_evaluation=lazy),\n",
    "            Zoom(zoom=0.75, keep_size=True, lazy_evaluation=lazy),\n",
    "            Rotate(angle=(0, 0, np.pi), mode=mode, align_corners=True, dtype=np.float64,\n",
    "                   lazy_evaluation=lazy),\n",
    "            # RandAffine(prob=0.5, rotate_range=np.pi, mode=\"nearest\"),\n",
    "            # ResizeWithPadOrCrop(100),\n",
    "            CastToType(dtype=torch.uint8),\n",
    "        ]\n",
    "    )\n",
    "    # print(transform._forward_transforms)\n",
    "    \n",
    "    # print(\"loader length =\", len(loader))\n",
    "    # fig, ax = plt.subplots(12, 3, figsize=(12, 48))\n",
    "    \n",
    "    results = [None for _ in range(num_rows * 3)]\n",
    "\n",
    "    for i_tx, tx in enumerate([transform_old, transform_new]):\n",
    "        # num workers = 0 for mac or gpu transforms\n",
    "        num_workers = 0 if sys.platform != \"linux\" or torch.cuda.is_available() else 2\n",
    "        base_dataset = Dataset(data, transform=base_images)\n",
    "        base_loader = DataLoader(base_dataset, num_workers=num_workers, batch_size=1)\n",
    "\n",
    "        dataset = Dataset(data, transform=tx)\n",
    "        # self.assertIsInstance(transform.inverse(dataset[0]), MetaTensor)\n",
    "        loader = DataLoader(dataset, num_workers=num_workers, batch_size=1)\n",
    "        inverter = Invert(transform=tx, nearest_interp=True, device=\"cpu\", post_func=torch.as_tensor)\n",
    "\n",
    "        for i_d, d in enumerate(base_loader):\n",
    "            d = decollate_batch(d)\n",
    "            for item in d:\n",
    "                print(item.shape)\n",
    "                if i_tx == 0:\n",
    "                    # results[i_d * 3] = item[0, ..., item.shape[-1] // 2]\n",
    "                    results[i_d * 3] = item\n",
    "\n",
    "        for i_d, d in enumerate(loader):\n",
    "            d = decollate_batch(d)\n",
    "            for item in d:\n",
    "                print(np.unique(item, return_counts=True))\n",
    "                orig = deepcopy(item)\n",
    "                i = inverter(item)\n",
    "                print(item.shape, i.shape)\n",
    "                # results[i_d * 3 + i_tx + 1] = i[0, ..., i.shape[-1] // 2]\n",
    "                results[i_d * 3 + i_tx + 1] = i\n",
    "        # check labels match\n",
    "        reverted = i.detach().cpu().numpy().astype(np.int32)\n",
    "        original = LoadImage(image_only=True)(data[-1])\n",
    "        n_good = np.sum(np.isclose(reverted, original.numpy(), atol=1e-3))\n",
    "        reverted_name = i.meta[\"filename_or_obj\"]\n",
    "        original_name = original.meta[\"filename_or_obj\"]\n",
    "        # self.assertEqual(reverted_name, original_name)\n",
    "        print(\"invert diff\", reverted.size - n_good)\n",
    "        # self.assertTrue((reverted.size - n_good) < 300000, f\"diff. {reverted.size - n_good}\")\n",
    "        set_determinism(seed=None)\n",
    "\n",
    "    # print(['None' if r is None else r.shape for r in results])\n",
    "    dl = DiceLoss(reduction=\"none\")\n",
    "    for r in range(num_rows):\n",
    "        r0 = results[r*3]\n",
    "        r0h = torch.nn.functional.one_hot(r0.long())\n",
    "        r0h = torch.squeeze(r0h, 0).permute(3, 0, 1, 2)\n",
    "        r1 = results[r*3+1]\n",
    "        r1h = torch.nn.functional.one_hot(r1.long())\n",
    "        r1h = torch.squeeze(r1h, 0).permute(3, 0, 1, 2)\n",
    "        print(r0h.shape, r1h.shape)\n",
    "        r2 = results[r*3+2]\n",
    "        r2h = torch.nn.functional.one_hot(r2.long())\n",
    "        r2h = torch.squeeze(r2h, 0).permute(3, 0, 1, 2)\n",
    "\n",
    "        print(r0h.shape)\n",
    "        dl1 = dl(r0h, r1h).mean(dim=(1,2,3))\n",
    "        dl2 = dl(r0h, r2h).mean(dim=(1,2,3))\n",
    "        \n",
    "        print(1 - dl1, 1 - dl2)\n",
    "\n",
    "    plot_datas([r[0, ..., find_mid_label_z(r)[2]] for r in results], 3, tight=True)\n",
    "    \n",
    "test_invert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c2b4f",
   "metadata": {},
   "source": [
    "## Invert version copied here after being run in a test file for debugging - can go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_invert():\n",
    "    import sys\n",
    "    from copy import deepcopy\n",
    "    from monai.utils import set_determinism\n",
    "    from tests.utils import assert_allclose, make_nifti_image    \n",
    "    from monai.data import DataLoader, Dataset, MetaTensor, create_test_image_3d, decollate_batch\n",
    "    from monai.transforms import (\n",
    "        CastToType,\n",
    "        Compose,\n",
    "        EnsureChannelFirst,\n",
    "        Invert,\n",
    "        LoadImage,\n",
    "        Orientation,\n",
    "        RandAffine,\n",
    "        RandAxisFlip,\n",
    "        RandFlip,\n",
    "        RandRotate,\n",
    "        RandRotate90,\n",
    "        RandZoom,\n",
    "        ResizeWithPadOrCrop,\n",
    "        Spacing,\n",
    "    )\n",
    "\n",
    "    mode = 'nearest'\n",
    "    set_determinism(seed=0)\n",
    "    im_fname = make_nifti_image(create_test_image_3d(101, 100, 107, noise_max=100)[1])  # label image, discrete\n",
    "    data = [im_fname for _ in range(12)]\n",
    "    lazy = True\n",
    "    base_images = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "        ]\n",
    "    )\n",
    "    transform_old = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            # Orientation(\"RPS\"),\n",
    "            old.Spacing(pixdim=(1.2, 1.01, 0.9), mode=mode, dtype=np.float32),\n",
    "            old.Flip(spatial_axis=[1, 2]),\n",
    "            old.Rotate90(spatial_axes=(1, 2)),\n",
    "            old.Zoom(zoom=0.75, keep_size=True),\n",
    "            old.Rotate(angle=(np.pi, 0, 0), mode=mode, align_corners=True, dtype=np.float64),\n",
    "            # RandAffine(prob=0.5, rotate_range=np.pi, mode=\"nearest\"),\n",
    "            # ResizeWithPadOrCrop(100),\n",
    "            CastToType(dtype=torch.uint8),\n",
    "        ]\n",
    "    )\n",
    "    transform_new = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True),\n",
    "            EnsureChannelFirst(),\n",
    "            # Orientation(\"RPS\"),\n",
    "            Spacing(pixdim=(1.2, 1.01, 0.9), mode=mode, dtype=np.float32, lazy_evaluation=lazy),\n",
    "            Flip(spatial_axis=[1, 2], lazy_evaluation=lazy),\n",
    "            Rotate90(spatial_axes=(1, 2), lazy_evaluation=lazy),\n",
    "            Zoom(zoom=0.75, keep_size=True, lazy_evaluation=lazy),\n",
    "            Rotate(angle=(0, 0, np.pi), mode=mode, align_corners=True, dtype=np.float64,\n",
    "                   lazy_evaluation=lazy),\n",
    "            # RandAffine(prob=0.5, rotate_range=np.pi, mode=\"nearest\"),\n",
    "            # ResizeWithPadOrCrop(100),\n",
    "            CastToType(dtype=torch.uint8),\n",
    "        ]\n",
    "    )\n",
    "#     print(transform._forward_transforms)\n",
    "    \n",
    "    # print(\"loader length =\", len(loader))\n",
    "    fig, ax = plt.subplots(12, 3, figsize=(12, 48))\n",
    "\n",
    "    for i_tx, tx in enumerate([transform_old, transform_new]):\n",
    "        # num workers = 0 for mac or gpu transforms\n",
    "        num_workers = 0 if sys.platform != \"linux\" or torch.cuda.is_available() else 2\n",
    "        base_dataset = Dataset(data, transform=base_images)\n",
    "        base_loader = DataLoader(base_dataset, num_workers=num_workers, batch_size=1)\n",
    "\n",
    "        dataset = Dataset(data, transform=tx)\n",
    "        # self.assertIsInstance(transform.inverse(dataset[0]), MetaTensor)\n",
    "        loader = DataLoader(dataset, num_workers=num_workers, batch_size=1)\n",
    "        inverter = Invert(transform=tx, nearest_interp=True, device=\"cpu\", post_func=torch.as_tensor)\n",
    "\n",
    "        for i_d, d in enumerate(base_loader):\n",
    "            d = decollate_batch(d)\n",
    "            for item in d:\n",
    "                print(item.shape)\n",
    "                if i_tx == 0:\n",
    "                    ax[i_d, 0].imshow(item[0, ..., item.shape[-1] // 2])\n",
    "\n",
    "        for i_d, d in enumerate(loader):\n",
    "            d = decollate_batch(d)\n",
    "            for item in d:\n",
    "                orig = deepcopy(item)\n",
    "                i = inverter(item)\n",
    "                print(item.shape, i.shape)\n",
    "                # self.assertTupleEqual(orig.shape[1:], (100, 100, 100))\n",
    "                # check the nearest interpolation mode\n",
    "                # assert_allclose(i.to(torch.uint8).to(torch.float), i.to(torch.float))\n",
    "                # self.assertTupleEqual(i.shape[1:], (101, 100, 107))\n",
    "                # print(i.shape)\n",
    "                ax[i_d, i_tx + 1].imshow(i[0, ..., i.shape[-1] // 2])\n",
    "        # check labels match\n",
    "        reverted = i.detach().cpu().numpy().astype(np.int32)\n",
    "        original = LoadImage(image_only=True)(data[-1])\n",
    "        n_good = np.sum(np.isclose(reverted, original.numpy(), atol=1e-3))\n",
    "        reverted_name = i.meta[\"filename_or_obj\"]\n",
    "        original_name = original.meta[\"filename_or_obj\"]\n",
    "        # self.assertEqual(reverted_name, original_name)\n",
    "        print(\"invert diff\", reverted.size - n_good)\n",
    "        # self.assertTrue((reverted.size - n_good) < 300000, f\"diff. {reverted.size - n_good}\")\n",
    "        set_determinism(seed=None)\n",
    "    \n",
    "test_invert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe4a64-b643-4766-833c-a7f6f06b6ab9",
   "metadata": {},
   "source": [
    "# Interpolation / resampling artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca170b-7eb5-409f-a3b0-301af5338368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "def generate_interpolation_artifacts():\n",
    "\n",
    "    t1 = torch.tensor([[[1.0, 0.0],[0.0, 1.0]]], dtype=torch.double)\n",
    "    t1 = t1.tile(1, 64, 64)\n",
    "    t2 = np.zeros((1, 4, 4))\n",
    "    t2[0, 0:2, 0:2] = 1.0\n",
    "    t2[0, 2:4, 2:4] = 1.0\n",
    "    t2 = torch.tensor(t2, dtype=torch.double)\n",
    "    t2 = t2.tile((1, 32, 32))\n",
    "    t4 = np.zeros((1, 8, 8))\n",
    "    t4[0, 0:4, 0:4] = 1.0\n",
    "    t4[0, 4:8, 4:8] = 1.0\n",
    "    t4 = torch.tensor(t4, dtype=torch.double)\n",
    "    t4 = t4.tile(1, 16, 16)\n",
    "\n",
    "    # starting_images = (t1,)\n",
    "    starting_images = (t1, t2, t4)\n",
    "\n",
    "    fig, ax = plt.subplots(len(starting_images), 4, figsize=(32, 4 * len(starting_images)))\n",
    "    if len(starting_images) == 1:\n",
    "        fig = [fig]\n",
    "        ax = [ax]\n",
    "    base_bin_vals = np.linspace(0.0, 1.0, 11)\n",
    "    bin_vals = torch.tensor(base_bin_vals, dtype=torch.double)\n",
    "    label_enums = [f\"{base_bin_vals[i]:1.1f}-{base_bin_vals[i+1]:1.1f}\" for i in range(0, 10)]\n",
    "    print(label_enums)\n",
    "    for j_t, t in enumerate(starting_images):\n",
    "    \n",
    "        scale = monai.transforms.Zoom(1.2, lazy=False)\n",
    "        inv_scale = monai.transforms.Zoom(1/1.2, lazy=False)\n",
    "\n",
    "        ts = list()\n",
    "        ts.append(t)\n",
    "        t = scale(t)\n",
    "        ts.append(t)\n",
    "        t = inv_scale(t)\n",
    "        ts.append(t)\n",
    "    \n",
    "        for i_t, t in enumerate(ts):\n",
    "            # tc = t[0:1, 48:80, 32:96]\n",
    "            tc = t[0:1, 56:72, 48:80]\n",
    "            # tc = t[0:1]\n",
    "            ax[j_t][i_t].imshow(tc[0], vmin=0.0, vmax=1.0)\n",
    "            ax[j_t][i_t].get_xaxis().set_visible(False)\n",
    "            ax[j_t][i_t].get_yaxis().set_visible(False)\n",
    "            # print(tc.dtype)\n",
    "            # print(i_t, tc.min(), tc.max(), torch.histogram(tc.to(dtype=torch.double), bin_vals))\n",
    "\n",
    "        hbefore = torch.histogram(ts[0][0, 56:72, 48:80].to(dtype=torch.double), bin_vals)\n",
    "        hafter = torch.histogram(ts[-1][0, 56:72, 48:80].to(dtype=torch.double), bin_vals)\n",
    "        ax[j_t][3].bar(bin_vals[:-1]-0.015, hbefore[0], width=0.06)\n",
    "        ax[j_t][3].bar(bin_vals[:-1]+0.015, hafter[0], width=0.06)\n",
    "        ax[j_t][3].set_xticks(bin_vals[:-1], label_enums, minor=False)\n",
    "        # ax[j_t][3].plot(bin_vals[:-1], hbefore[0])\n",
    "        # ax[j_t][3].plot(bin_vals[:-1], hafter[0])\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    plt.savefig(\"moire_artifacts.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "generate_interpolation_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b992e1-3967-4746-a0cb-b47dadacd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolation_artifacts_minimal():\n",
    "    t1 = torch.tensor([[[1.0, 0.0],[0.0, 1.0]]], dtype=torch.double)\n",
    "    t1 = t1.tile(1, 64, 64)\n",
    "    t2 = np.zeros((1, 4, 4))\n",
    "    t2[0, 0:2, 0:2] = 1.0\n",
    "    t2[0, 2:4, 2:4] = 1.0\n",
    "    t2 = torch.tensor(t2, dtype=torch.double)\n",
    "    t2 = t2.tile((1, 32, 32))\n",
    "    t4 = np.zeros((1, 8, 8))\n",
    "    t4[0, 0:4, 0:4] = 1.0\n",
    "    t4[0, 4:8, 4:8] = 1.0\n",
    "    t4 = torch.tensor(t4, dtype=torch.double)\n",
    "    t4 = t4.tile(1, 16, 16)\n",
    "\n",
    "    # starting_images = (t1,)\n",
    "    starting_images = (t4,)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(32, 8))\n",
    "    if len(starting_images) == 1:\n",
    "        fig = [fig]\n",
    "        ax = [ax]\n",
    "    base_bin_vals = np.linspace(0.0, 1.0, 11)\n",
    "    bin_vals = torch.tensor(base_bin_vals, dtype=torch.double)\n",
    "    label_enums = [f\"{base_bin_vals[i]:1.1f}-{base_bin_vals[i+1]:1.1f}\" for i in range(0, 10)]\n",
    "    print(label_enums)\n",
    "    for j_t, t in enumerate(starting_images):\n",
    "    \n",
    "        scale = monai.transforms.Zoom(1.2, lazy=False)\n",
    "        inv_scale = monai.transforms.Zoom(1/1.2, lazy=False)\n",
    "\n",
    "        ts = list()\n",
    "        ts.append(t)\n",
    "        t = scale(t)\n",
    "        # ts.append(t)\n",
    "        t = inv_scale(t)\n",
    "        ts.append(t)\n",
    "    \n",
    "        for i_t, t in enumerate(ts):\n",
    "            # tc = t[0:1, 48:80, 32:96]\n",
    "            tc = t[0:1, 48:80, 48:80]\n",
    "            # tc = t[0:1]\n",
    "            ax[j_t][i_t].imshow(tc[0], vmin=0.0, vmax=1.0)\n",
    "            ax[j_t][i_t].get_xaxis().set_visible(False)\n",
    "            ax[j_t][i_t].get_yaxis().set_visible(False)\n",
    "            # print(tc.dtype)\n",
    "            # print(i_t, tc.min(), tc.max(), torch.histogram(tc.to(dtype=torch.double), bin_vals))\n",
    "\n",
    "        hbefore = torch.histogram(ts[0][0, 48:80, 48:80].to(dtype=torch.double), bin_vals)\n",
    "        hafter = torch.histogram(ts[-1][0, 48:80, 48:80].to(dtype=torch.double), bin_vals)\n",
    "        ax[j_t][2].bar(bin_vals[:-1]-0.015, hbefore[0], width=0.06)\n",
    "        ax[j_t][2].bar(bin_vals[:-1]+0.015, hafter[0], width=0.06)\n",
    "        ax[j_t][2].set_ylabel(\"pixel count\", fontsize=20)\n",
    "        ax[j_t][2].set_yticks((0, 64, 128, 192, 256, 320, 384, 448, 512), (0, 64, 128, 192, 256, 320, 384, 448, 512), fontsize=20)\n",
    "        ax[j_t][2].set_xlabel(\"pixel values\", fontsize=20)\n",
    "        ax[j_t][2].set_xticks(bin_vals[:-1], label_enums, minor=False, fontsize=20, rotation=45)\n",
    "        # ax[j_t][3].plot(bin_vals[:-1], hbefore[0])\n",
    "        # ax[j_t][3].plot(bin_vals[:-1], hafter[0])\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    plt.savefig(\"moire_artifacts_minimal.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "generate_interpolation_artifacts_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ddfc9-4252-43b6-9a82-2e5cb85ae444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolation_artifacts_image():\n",
    "\n",
    "    t4 = np.zeros((1, 16, 16))\n",
    "    t4[0, 0:8, 0:8] = 1.0\n",
    "    t4[0, 8:16, 8:16] = 1.0\n",
    "    t4 = torch.tensor(t4, dtype=torch.double)\n",
    "    t4 = t4.tile(1, 8, 8)\n",
    "\n",
    "    scale = monai.transforms.Zoom(1.2, lazy=False)\n",
    "    inv_scale = monai.transforms.Zoom(1/1.2, lazy=False)\n",
    "\n",
    "    base_bin_vals = np.linspace(0.0, 1.0, 11)\n",
    "    bin_vals = torch.tensor(base_bin_vals, dtype=torch.double)\n",
    "    label_enums = [f\"{base_bin_vals[i]:1.1f}-{base_bin_vals[i+1]:1.1f}\" for i in range(0, 10)]\n",
    "\n",
    "    hgrams = list()\n",
    "    hgrams.append(torch.histogram(t4[0, 48:80, 48:80].to(dtype=torch.double), bin_vals))\n",
    "    iterations = 2\n",
    "    to_show = (0, iterations // 2, iterations)\n",
    "    for _ in range(iterations):\n",
    "        t4 = scale(t4)\n",
    "        t4 = inv_scale(t4)\n",
    "        hgrams.append(torch.histogram(t4[0, 48:80, 48:80].to(dtype=torch.double), bin_vals))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    # ax.imshow(t4[0])\n",
    "    ax.bar(bin_vals[:-1]-0.01, hgrams[to_show[0]][0], width=0.04, label=\"original\")\n",
    "    ax.bar(bin_vals[:-1], hgrams[to_show[1]][0], width=0.04, label=f\"{to_show[1]} resamples\" if to_show[1] != 1 else f\"{to_show[1]} resample\")\n",
    "    ax.bar(bin_vals[:-1]+0.01, hgrams[to_show[2]][0], width=0.04, label=f\"{to_show[2]} resamples\")\n",
    "    ax.set_ylabel(\"pixel count\", fontsize=20)\n",
    "    ax.set_yticks((0, 64, 128, 192, 256, 320, 384, 448, 512), (0, 64, 128, 192, 256, 320, 384, 448, 512), fontsize=20)\n",
    "    ax.set_xlabel(\"pixel values\", fontsize=20)\n",
    "    ax.set_xticks(bin_vals[:-1], label_enums, minor=False, fontsize=20, rotation=45)\n",
    "    ax.legend(loc=9, fontsize=20)\n",
    "    plt.savefig(\"hgram_for_grid.svg\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "generate_interpolation_artifacts_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f9ff0-87a9-495f-acf1-0438f5cdace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolation_artifacts_brain_rotation_hgram():\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # t4 = np.zeros((1, 16, 16))\n",
    "        # t4[0, 0:8, 0:8] = 1.0\n",
    "        # t4[0, 8:16, 8:16] = 1.0\n",
    "        # t4 = torch.tensor(t4, dtype=torch.double)\n",
    "        # t4 = t4.tile(1, 8, 8)\n",
    "        t4 = torch.tensor(display_images[\"forward_images_patch\"][0])\n",
    "        t4 = t4[None, ...]\n",
    "        print(t4.shape)\n",
    "        \n",
    "        scale = monai.transforms.Zoom(1.2, lazy=False)\n",
    "        inv_scale = monai.transforms.Zoom(1/1.2, lazy=False)\n",
    "        \n",
    "        base_bin_vals = np.linspace(0.0, 1024.0, 65)\n",
    "        bin_vals = torch.tensor(base_bin_vals, dtype=torch.double)\n",
    "        print(bin_vals)\n",
    "        # label_enums = [f\"{base_bin_vals[i]:1.1f}-{base_bin_vals[i+1]:1.1f}\" for i in range(0, len(base_bin_vals)-1)]\n",
    "        label_enums = [f\"{int(base_bin_vals[i])}-{int(base_bin_vals[i+1])}\" for i in range(0, len(base_bin_vals)-1)]\n",
    "        \n",
    "        hgrams = list()\n",
    "        # hgrams.append(torch.histogram(t4[0, 48:80, 48:80].to(dtype=torch.double), bin_vals))\n",
    "        hgrams.append(torch.histogram(t4[0].to(dtype=torch.double), bin_vals))\n",
    "        print(hgrams)\n",
    "        iterations = 2\n",
    "        # legends = \n",
    "        for _ in range(iterations):\n",
    "            t4 = scale(t4)\n",
    "            t4 = inv_scale(t4)\n",
    "            # hgrams.append(torch.histogram(t4[0, 48:80, 48:80].to(dtype=torch.double), bin_vals))\n",
    "            hgrams.append(torch.histogram(t4[0].to(dtype=torch.double), bin_vals))\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        # ax.imshow(t4[0])\n",
    "        x_vals = bin_vals / 1024\n",
    "        # ax.bar(x_vals[:-1]-0.01, hgrams[0][0], width=0.03)\n",
    "        # ax.bar(x_vals[:-1], hgrams[2][0], width=0.03)\n",
    "        # ax.bar(x_vals[:-1]+0.01, hgrams[4][0], width=0.03)\n",
    "        to_show = (0, iterations // 2, iterations)\n",
    "        ax.plot(bin_vals[1:-1], hgrams[to_show[0]][0][1:], label=\"original\")\n",
    "        ax.plot(bin_vals[1:-1], hgrams[to_show[1]][0][1:], label=f\"{to_show[1]} resamples\")\n",
    "        ax.plot(bin_vals[1:-1], hgrams[to_show[2]][0][1:], label=f\"{to_show[2]} resamples\")\n",
    "        ax.set_ylabel(\"pixel count\", fontsize=20)\n",
    "        pixel_count_values = [i * 256 for i in range(9)]\n",
    "        ax.set_yticks(pixel_count_values, pixel_count_values, fontsize=20)\n",
    "        # ax.set_yticks((0, 64, 128), (0, 64, 128), fontsize=20)\n",
    "        ax.set_xlabel(\"pixel values\", fontsize=20)\n",
    "        # ax.set_xticks(x_vals[:-1], label_enums, minor=False, fontsize=20, rotation=45)\n",
    "        tick_vals = np.linspace(0, 1024, 9)\n",
    "        tick_labels = tick_vals\n",
    "        ax.set_xticks(tick_vals, tick_labels, minor=False, fontsize=20, rotation=45)\n",
    "        ax.legend()\n",
    "\n",
    "generate_interpolation_artifacts_brain_rotation_hgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b7a89-14fb-4be9-a871-0281ff1825a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolation_artifacts_brain_rotation_images():\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t4 = torch.tensor(display_images[\"forward_images_patch\"][0])\n",
    "        t4 = t4[None, ...]\n",
    "        print(t4.shape)\n",
    "        \n",
    "        scale = monai.transforms.Zoom(1.2, lazy=False)\n",
    "        inv_scale = monai.transforms.Zoom(1/1.2, lazy=False)\n",
    "\n",
    "        iterations = 8\n",
    "        to_show = (0, 2, iterations)\n",
    "        results = [t4]\n",
    "        # fig, ax = plt.subplots(1, 3, figsize=(8, 6))\n",
    "        for _ in range(iterations):\n",
    "            t4 = scale(t4)\n",
    "            t4 = inv_scale(t4)\n",
    "            results.append(t4)\n",
    "        xslice = slice(20, 200)\n",
    "        yslice = slice(30, 210)\n",
    "        # ax[0].imshow(results[0][0, yslice, xslice], label=\"original\")\n",
    "        \n",
    "        # ax[1].imshow(results[to_show[1]][0, yslice, xslice], label=f\"{to_show[1]} resamples\")\n",
    "        # ax[2].imshow(results[to_show[2]][0, yslice, xslice], label=f\"{to_show[2]} resamples\")\n",
    "\n",
    "        _index = 2\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.imshow(results[to_show[_index]][0, yslice, xslice])\n",
    "        plt.savefig(f\"image_deg_{_index}.svg\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "generate_interpolation_artifacts_brain_rotation_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b053b7-7bf0-4145-acbe-c67eb27c3c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b332c8d",
   "metadata": {},
   "source": [
    "# Figure generation for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c230a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = display_images.keys()\n",
    "keys = (\"forward_images_patch\", \"round_trip_whole\")\n",
    "titles = {\n",
    "    \"forward_images_patch\": (\"Original image\", \"Patch-first: traditional\", \"Patch-first: lazy\"),\n",
    "    \"round_trip_whole\": (\"Original labels\", \"Round trip labels: traditional\", \"Round trip labels: lazy\")\n",
    "}\n",
    "# for k in keys:\n",
    "#     print(k)\n",
    "#     v = display_images[k]\n",
    "#     print(v[0].shape)\n",
    "#     plot_datas(v, cols=3, tight=True, axis=False, titles=titles[k])\n",
    "values = display_images[\"forward_images_patch\"] + display_images[\"round_trip_whole\"]\n",
    "titles = titles[\"forward_images_patch\"] + titles[\"round_trip_whole\"]\n",
    "plot_datas(values, cols=3, tight=True, axis=False, titles=titles, font='timesnewroman')\n",
    "plt.savefig(\"images_trad_vs_lazy.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73b8df-147c-4b2b-b3ca-f33ea3f0b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _name = \"forward_images_patch\"\n",
    "_name = \"round_trip_whole\"\n",
    "_index = 2\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.imshow(display_images[_name][_index])\n",
    "plt.savefig(f\"img_{_name}_{_index}.svg\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23080702",
   "metadata": {},
   "source": [
    " # Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef77d2",
   "metadata": {},
   "source": [
    "# 3D rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3608d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_img((32, 32, 8))\n",
    "dmax = data.max()\n",
    "data[0,7:9,7:9, :] = dmax + 32\n",
    "data[0,15:17,:, :] = dmax + 64\n",
    "data[0,0,:, :] = dmax + 96\n",
    "data[0,:,0, :] = dmax + 128\n",
    "print(data.shape)\n",
    "r = Rotate((0, 0, torch.pi / 4), keep_size=False, padding_mode=\"zeros\")\n",
    "\n",
    "data1 = r(data)\n",
    "\n",
    "plt.imshow(data1[0,...,4], vmin=data.min(), vmax=data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d864b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ben/data/Task07_Pancreas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faff95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for r, d, f in os.walk(os.path.join(data_path, 'imagesTr')):\n",
    "    for fn in f:\n",
    "        entries.append(os.path.join(r, fn))\n",
    "entries = sorted(entries)\n",
    "for e in entries:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = LoadImage('nibabelreader')\n",
    "c = AddChannel()\n",
    "r = Rotate90(k=1, spatial_axes=(0, 2))\n",
    "\n",
    "data = os.path.join(data_path, 'imagesTr', 'pancreas_001.nii.gz')\n",
    "data = i(data)[0]\n",
    "data = c(data)\n",
    "md1 = dict(data.meta)\n",
    "data = r(data)\n",
    "md2 = dict(data.meta)\n",
    "\n",
    "keys = sorted(set(md1.keys()).union(md2.keys()))\n",
    "print(keys)\n",
    "for k in keys:\n",
    "    v1 = md1.get(k, None)\n",
    "    v2 = md2.get(k, None)\n",
    "    if isinstance(v1, np.ndarray):\n",
    "        if np.isnan(v1).all() and np.isnan(v2).all():\n",
    "            equiv = True\n",
    "        else:\n",
    "            equiv = np.allclose(v1, v2)\n",
    "    elif isinstance(v1, torch.Tensor):\n",
    "        equiv = torch.allclose(v1, v2)\n",
    "    else:\n",
    "        equiv = v1 == v2\n",
    "\n",
    "    print(k, equiv)\n",
    "    if not equiv:\n",
    "        print(\"v1:\", v1)\n",
    "        print(\"v2:\", v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5\n",
    "b = None\n",
    "print(b or a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn = 0\n",
    "rtn = torch.pi / 4\n",
    "rsin = math.sin(rtn)\n",
    "rcos = math.cos(rtn)\n",
    "\n",
    "mt = np.asarray([[1.0, 0.0, -8.0],\n",
    "                 [0.0, 1.0, -8.0],\n",
    "                 [0.0, 0.0, 1.0]])\n",
    "\n",
    "mid = np.asarray([[1.0, 0.0, 0.0],\n",
    "                 [0.0, 1.0, 0.0],\n",
    "                 [0.0, 0.0, 1.0]])\n",
    "\n",
    "mrpre = np.asarray([[1.0, 0.0, -16.0],\n",
    "                    [0.0, 1.0, -16.0],\n",
    "                    [0.0, 0.0, 1.0]])\n",
    "\n",
    "mr = np.asarray([[rcos, -rsin, 0.0],\n",
    "                [rsin, rcos, 0.0],\n",
    "                [0.0, 0.0, 1.0]])\n",
    "\n",
    "mrpost = np.asarray([[1.0, 0.0, 16.0],\n",
    "                    [0.0, 1.0, 16.0],\n",
    "                    [0.0, 0.0, 1.0]])\n",
    "\n",
    "m1 = mt\n",
    "m2 = mr @ m1\n",
    "\n",
    "print(\"m1\\n\", m1)\n",
    "print(\"m2\\n\", m2)\n",
    "\n",
    "vs = [np.asarray([8.0, 8.0, 1.0]), np.asarray([0.0, 0.0, 1.0]), np.asarray([0.0, 32.0, 1.0]),\n",
    "      np.asarray([32.0, 0.0, 1.0]), np.asarray([32.0, 32.0, 1.0])]\n",
    "\n",
    "cs0 = ['#007f00', '#7f0000', '#7f0000', '#7f0000', '#7f0000']\n",
    "cs1 = ['#3faf3f', '#af3f3f', '#af3f3f', '#af3f3f', '#af3f3f']\n",
    "cs2 = ['#7fdf7f', '#df7f7f', '#df7f7f', '#df7f7f', '#df7f7f']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(-50, 50)\n",
    "for c, v in zip(cs0, vs):\n",
    "    mv = mid @ v\n",
    "    ax.scatter(mv[0], mv[1], color=c)\n",
    "    \n",
    "for c, v in zip(cs1, vs):\n",
    "    mv = m1 @ v\n",
    "    print(v, mv)\n",
    "    plt.scatter(mv[0], mv[1], color=c)\n",
    "\n",
    "for c, v in zip(cs2, vs):\n",
    "    mv = m2 @ v\n",
    "    print(v, mv)\n",
    "    plt.scatter(mv[0], mv[1], color=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a37b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tc = torch.nn.ConvTranspose3d(32,\n",
    "                              32,\n",
    "                              kernel_size=3,\n",
    "                              stride=(2, 2, 1),\n",
    "                              padding=(1, 1, 1),\n",
    "                              output_padding=(1, 1, 0)\n",
    "                             )\n",
    "\n",
    "t = torch.Tensor(np.zeros((1, 32, 64, 64, 16)))\n",
    "print(t.shape)\n",
    "\n",
    "t_ = tc.forward(t)\n",
    "print(t_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae60eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e13fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de1ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f77af-0cfd-4253-9550-f7927a6d2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking entropy\n",
    "\n",
    "import scipy\n",
    "#i = np.random.uniform(size=(64,64))\n",
    "i = np.zeros((64, 64))\n",
    "print(entries_[0])\n",
    "i = nib.load(entries_[0][1][0]).get_fdata()[:, :, 80, 0]\n",
    "# i[24:32, 40:56] = 1\n",
    "j = scipy.ndimage.gaussian_filter(i, sigma=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(i)\n",
    "ax[1].imshow(j)\n",
    "print(entropy(i))\n",
    "print(entropy(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1760a9-d501-44b4-8f0b-bf2710e15feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "fns = fm.findSystemFonts()\n",
    "for fn in fns:\n",
    "    if 'Times' in fn:\n",
    "        print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8feea-f656-4d42-8b94-8161bd190208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
